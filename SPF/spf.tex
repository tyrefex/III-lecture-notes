\documentclass[12pt]{article}

\usepackage{ishn}

\makeindex[intoc]

\begin{document}

\hypersetup{pageanchor=false}
\begin{titlepage}
	\begin{center}
		\vspace*{1em}
		\Huge
		\textbf{III Symmetries, Particles and Fields}

		\vspace{1em}
		\large
		Ishan Nath, Michaelmas 2024

		\vspace{1.5em}

		\Large

		Based on Lectures by Prof. Matthew Wingate

		\vspace{1em}

		\large
		\today
	\end{center}
	
\end{titlepage}
\hypersetup{pageanchor=true}

\tableofcontents

\newpage

% lecture 1

\section{Introduction to Symmetries}%
\label{sec:intro_sym}

Recall Newton's second law:
\[
m \frac{\diff^2 \mathbf{x}}{\diff t^2} = \mathbf{F}(\mathbf{x}).
\]
This simplifies if we know $F$ is rotationally symmetric, i.e. $\mathbf{F}(\mathbf{x}) = F(r) \mathbf{\hat r}$. Then $\mathbf{L} = \mathbf{x} \times \mathbf{p}$ is conserved, and trajectories lie in planes containing the origin.

Now consider Lagrangian mechanics, with Lagrangian $L(q_i, \dot q_i, t)$. The principle of least action says
\[
S = \int_{t_1}^{t_2} \diff t \, L(q_i(t), \dot q_i(t), t)
\]
is minimized by classical trajectories. Hence Euler-Lagrange gives
\[
\frac{\partial L}{\partial q_i} - \frac{\diff}{\diff t} \left( \frac{\partial L}{\partial \dot q_i} \right) = 0.
\]
N\"oether's theorem says that invariance of $L$ under some coordinate transform corresponds to an associated conserved quantity.

\begin{exbox}
	Consider a particle in three dimension, with a potential:
	\[
	L = \frac{1}{2} m (\dot x^2 + \dot y^2 + \dot z^2) - U(x, y, z),
	\]
	which is independent of $t$, hence invariant under $t \mapsto t + \delta t$. This implies that the Hamiltonian $H = T + U$ is conserved. If we transform into canonical momenta $p_i = \frac{\partial L}{\partial \dot x_i} = m \dot x_i$, then
	\[
	H(x_i, p_i, t) = \sum \dot x_i p_i - L = \sum \dot x_i \frac{\partial L}{\partial \dot x_i} - L
	\]
	is invariant by Euler-Lagrange:
	\[
	\frac{\diff H}{\diff t} = \sum \ddot x_i \frac{\partial L}{\partial \dot x_i} - \sum x_i \frac{\diff}{\diff t} \left( \frac{\partial L}{ \partial \dot x_i} \right) - \dot x_i \frac{\partial L}{\partial x_i} - \ddot x_i \frac{\partial L}{\partial \dot x_i} - \frac{\partial L}{\partial t} = 0.
	\]

	If $L$ is invariant under $x \mapsto x + \delta x$, then
	\[
		\frac{\partial L}{\partial x} = 0 \implies \frac{\partial L}{\partial \dot x} = p_x = \text{constant}.
	\]
	If $L$ is invariant under rotations about the $z$-axis, then the $z$-component of angular momentum, $xp_y - yp_x$, is constant. The best way to see is transform $L$ into cylindrical coordinates:
	\[
	L = \frac{1}{2} m (\dot \rho^2 - \rho^2 \dot \theta + \dot z^2) - U(\rho, z).
	\]
	So the invariance under rotations means
	\[
	\frac{\partial L}{\partial \theta} = 0 \implies \frac{\partial L}{\partial \dot \theta} = 0 = m \rho^2 \dot \theta = xp_y - yp_x
	\]
	is constant.
\end{exbox}

\subsection{Symmetries in Quantum Mechanics}%
\label{sub:sym_qm}

Given a system whose states are element of a Hilbert space $\mathcal{H}$, a symmetry means there exists some invertible operator $U$ acting on $\mathcal{H}$ which preserves inner products, up to an overall phase $e^{i\phi}$.

\begin{definition}
	Let $\ket \psi, \ket \phi$ be any normalized vectors in $\mathcal{H}$. Denote $\ket{U \psi} = U \ket \psi$, and $\ket{U \phi} = U \ket \phi$.

	$U$ is a \emph{symmetry transformation}\index{symmetry transformation} if
	\[
		|\braket{U\phi | U \psi}| = |\braket{\phi|\psi}|.
	\]
\end{definition}

\begin{proposition}[Wigner's Theorem]
	Symmetry transformation operators are either linear and unitary, or antilinear and antiunitary.
\end{proposition}

Antilinear and antiunitary means
\[
U(a\ket \psi + \beta \ket \phi) = a^\ast U \ket \psi + b^\ast U \ket \phi,
\]
\[
	\braket{U\phi | U\psi} = \braket{\phi|\psi}^\ast.
\]

Suppose we have a system with a time-independent Hamiltonian. Then we can write down
\[
	\braket{\psi(t)}=  e^{-iHt} \ket{\psi(0)},
\]
by Schr\"odinger's equation with $\hbar = 1$. In the first case, note
\begin{align*}
	\braket{U \phi | U \psi(t)} &= \braket{\phi|\psi(t)} \\
				    &= \braket{\phi | e^{-iHt}| \psi(0)}.
\end{align*}

We should find the same result by transforming $\ket{\psi(0)}$ before time evolution:
\begin{align*}
	\braket{U\phi | U \psi(t)} &= \braket{U\phi | e^{-iHt} | U\psi(0)} \\
				   &= \braket{\phi | U^{\dagger} e^{-iHt} U | \psi(0)}.
\end{align*}
Equating these, we find
\[
	U^{\dagger} e^{-iHt}U = e^{-iHt} \implies [U, H] = 0.
\]

\begin{exbox}
	If $H$ commutes with $\mathbf{p}$, then $H$ cannot depend on $\mathbf{x}$, as
	\[
		[x_i, p_j] = i \delta_{ij} \neq 0
	\]
	generally. So $H$ is invariant under translation $\mathbf{x} \mapsto \mathbf{x} + \mathbf{a}$, and this is generated by unitary operators $\exp(i \mathbf{p} \cdot \mathbf{a})$.

	If $H$ is rotationally symmetric, then any momentum operator $\mathbf{J}$ or $\mathbf{L}$ commutes with $H$.
\end{exbox}

\newpage

\section{Lie Groups and Algebras}%
\label{sec:lie_g_alg}

\subsection{Lie Groups}%
\label{sub:lie_g}

Recall the definition of a group: a set together with a relation which has an identity, inverses and is associative.

Also recall a group is abelian if $g \cdot h = h \cdot g$ for all $g, h \in G$.

% lecture 2

\begin{definition}
	A \emph{manifold}\index{manifold} is a space which looks Euclidean, like $\mathbb{R}^n$, on small scales, in small neighbourhoods.

	A \emph{differentiable manifold}\index{differentiable manifold} is one which satisfies certain smoothness conditions.
\end{definition}

\begin{definition}
	A \emph{Lie group}\index{Lie group} consists of a differentiable manifold $G$ along with a binary operation $\cdot$, such that the group axioms hold, and that $\cdot$ and inverse are smooth operations.
\end{definition}

\subsection{Matrix Lie Groups}%
\label{sub:mlg}

For example, the general linear group $\mathsf{GL}(n, \mathbb{F})$ is the group of invertible $n \times n$ matrices over a field $\mathbb{F}$. So,
\[
	\mathsf{GL}(n, \mathbb{F}) = \{ M \in \mathrm{Mat}_n(\mathbb{F}) \mid \det M \neq 0\}.
\]
The group operation is simply matrix multiplication.

The dimension of $\mathsf{GL}(n, \mathbb{R})$ is $n^2$, as there are $n^2$ free parameters. For $\mathsf{GL}(n, \mathbb{C})$, we have real dimension $2n^2$, and complex dimension $n^2$.

Important subgroups of $\mathsf{GL}(n, \mathbb{F})$ are:
\begin{itemize}
	\item The special linear group
		\[
			\mathsf{SL}(n, \mathbb{F}) = \{M \in \mathsf{GL}(n, \mathbb{F}) \mid \det M = 1\}.
		\]
	\item $\mathsf{SL}(n, \mathbb{R})$ has dimension $n^2 - 1$.
	\item The orthogonal group
		\[
			\mathsf O(n) = \{M \in \mathsf{GL}(n, \mathbb{R}) \mid M^T M = I\}.
		\]
		This implies $\det M = \pm 1$. We can also define
		\[
			\mathsf{SO}(n) = \{M \in \mathsf O(n) \mid \det M = 1\}.
		\]
	\item Pseudo-orthogonal group. Define an $(n + m) \times (n + m)$ matrix by
		\[
		\eta =
		\begin{pmatrix}
			I_n & 0 \\
			0 & -I_M
		\end{pmatrix}.
		\]
		Then we can define
		\[
			\mathsf{O}(n, m) = \{M \in \mathsf{GL}(n + m, \mathbb{R}) \mid M^T \eta M = \eta\}.
		\]
		Note $M \in \mathsf{SO}(n, m) \iff \det M = 1$.
	\item Unitary.
		\[
			\mathsf{U}(n) = \{ M \in \mathsf{GL}(n, \mathbb{C}) \mid M^{\dagger} M = I\}.
		\]
		Similarly have $\mathsf{SU}(n)$.
	\item Pseudounitary.
		\[
			\mathsf{U}(n, m) = \{M \in \mathsf{GL}(n, \mathbb{C}) \mid M^{\dagger} \eta M = \eta\}.
		\]
	\item Symplectic group. Define a fixed, antisymmetric $2n \times 2n$ matrix, e.g.
		\[
		\Omega =
		\begin{pmatrix}
			0 & I_n \\
			-I_n & 0
		\end{pmatrix}.
		\]
		Then,
		\[
			\mathsf{Sp}(2n, \mathbb{R}) = \{M \in \mathsf{GL}(2n, \mathbb{R}) \mid M^{T} \Omega M = \Omega\}.
		\]
		We can show that $\det M = 1$ using the Pfaffian.
\end{itemize}

\begin{definition}
	Given a $2n \times 2n$ antisymmetric matrix $A$, its \emph{Pfaffian}\index{Pfaffian} is given by
	\[
	\mathrm{Pf} A = \frac{1}{2^n n!} \eps_{i_1 i_2 \cdots i_{2n}} A_{i_1 i_2} A_{i_3 i_4} \cdots A_{i_{2n-1} i_{2n}}.
	\]
\end{definition}

\subsection{Group Elements as Transformations}%
\label{sub:ge_t}

We can define actions of group elements $g \in G$ on a set $X$.

\begin{definition}
	The \emph{left action}\index{left action} of $G$ on $X$ is a map $L : G \times X \to X$ such that $L(e, x) = x$, and
	\[
	L(g_2, L(g_1, x)) = L(g_2 g_1, x),
	\]
	for all $x \in X$ and $g_1, g_2 \in G$. In more usual notation, for all $g \in G$, we can associate a map $g : X \to X$ as $g(x) = gx$.
\end{definition}

\begin{definition}
	The \emph{right action}\index{right action} of $G$ on $X$ is defined by $g : X \to X$ such that $g(x) = xg^{-1}$, for all $x \in X$, $g \in G$. The inverse preserves under composition, so
	\[
	g_2(g_1(x)) = x g_1^{-1} g_2^{-1} = (g_2 g_1)(x).
	\]
\end{definition}

\begin{definition}
	The action of \emph{conjugation}\index{conjugation} by $G$ on $X$ is the action defined by
	\[
	g(x) = g x g^{-1},
	\]
	for $g \in G$, $x \in X$.
\end{definition}

\begin{definition}
	Given a group $G$ and a set $X$, an \emph{orbit}\index{orbit} of an element $x \in X$ is the set of elements of $X$ in the image of $G$.
\end{definition}

\begin{exbox}
	If the action is a left action, then the orbit of $x \in X$ is
	\[
		Gx = \{gx \mid g \in G\}.
	\]
\end{exbox}

It can be shown that the set of orbits under $G$ partition $X$.

In $\mathbb{R}^n$, orthogonal matrices $\mathsf{O}(n)$ represent rotations and reflections, and preserve the inner product; similarly for $\mathsf{U}(n)$.

We can parametrize $\mathsf{SO}(2)$ as
\[
\mathsf{SO}(2) = \left\{ R(\theta) =
	\begin{pmatrix}
		\cos \theta & - \sin \theta \\
		\sin \theta & \cos \theta
	\end{pmatrix}
	 \biggm|  \theta \in [0, 2\pi]\right\}.
\]
$\cos$, $\sin$ are smooth. We can show that $R(\theta_2)R(\theta_1) = R(\theta_1 + \theta_2)$.

$\mathsf{SO}(3)$ gives rotations of vectors in $\mathbb{R}^3$. The axis of rotation is given by a unit vector $\mathbf{n} \in S^2$, and we also have an angle $\theta$.

Note that rotation by $\theta \in [-\pi, 0]$ about $\mathbf{n}$ is equivalent to rotation by $-\theta$ about $- \mathbf{n}$, so we can confine $\theta \in [0, \pi]$.

Hence we can depict the manifold of $\mathsf{SO}(3)$ as a ball of radius $\pi$ in $\mathbb{R}^3$, where antipodal points are identified: $\pi \mathbf{n} = - \pi \mathbf{n}$.

% lecture 3

The \emph{pseudo-orthogonal group}\index{pseudo-orthogonal group} $\mathsf{SO}(n, m)$ act on vectors in $\mathbb{R}^{n + m}$, and preserve the scalar product $v_2^T \eta v_1$ for $v_1, v_2 \in \mathbb{R}^{n+m}$.

For example,
\[
\mathsf{SO}(1, 1) = \left\{
	\begin{pmatrix}
		\cosh \psi & \sinh \psi \\
		\sinh \psi & \cosh \psi
	\end{pmatrix}
\biggm| \psi \in \mathbb{R} \right\}.
\]
$\mathsf{SO}(1, 1)$ is an example of a non-compact group.

\subsection{Parametrization of Lie Groups}%
\label{sub:param_lie}

At least in small neighbourhoods, we can assign coordinates
\[
x = (x^1, \ldots, x^n) \in \mathbb{R}^n,
\]
such that $g(x) \in G$. Closure says that $g(y) g(x) = g(z)$, and smoothness says that the components of $z$ are continuously differentiable functions of $x$ and $y$, so
\[
z^n = \phi^n(x, y).
\]
We can choose the coordinates at the origin such that $g(0) = e$. Then $g(0) g(x) = g(x)$, so
\[
\phi^r(x, 0) = x^r, \qquad \phi^r(0, y) = y^r.
\]
From inverses, for each $x$ there exists $\bar x$ such that $g(\bar x) = g(x)^{-1}$, hence
\[
\phi^r(\bar x, x) = 0 = \phi^r(x, \bar x).
\]
Finally, associativity means $g(z)[g(y)g(x)] = [g(z)g(y)]g(x)$, hence
\[
\phi^r(\phi(x, y), z) = \phi^r(x, \phi(y, z)).
\]
\subsection{Lie Algebras}%
\label{sub:lie_a}

Lie groups are hard to quantify. Instead, we look at lie algebras, which are a linearization of the lie group.

A lie group is homogeneous: any neighbourhood can be mapped to any other neighbourhood. We will linearize near the identity of $G$.

\begin{definition}
	A \emph{Lie algebra}\index{Lie algebra} is a vector space $V$, which additionally has a vector product, the \emph{Lie bracket}\index{Lie bracket} $[\cdot, \cdot] : V \times V \to V$ possessing the following properties: for $X, Y, Z \in V$,
	\begin{enumerate}
		\item antisymmetry: $[X, Y] = -[Y, X]$.
		\item Jacobi identity: $[X, [Y, Z]] + [Y, [X, Z]] + [Z, [X, Y]] = 0$.
		\item linearity: for $\alpha, \beta \in \mathbb{F}$, $[\alpha X + \beta Y, Z] = \alpha[X, Z] + \beta[Y, Z]$.
	\end{enumerate}
\end{definition}

\begin{remark}
	Any vector space which has a vector product $\ast$ can be made into a Lie algebra with Lie bracket
	\[
		[X, Y] = X\ast Y - Y\ast X.
	\]
\end{remark}

Given a Lie algebra $V$, choose a basis $\{T_a\}$. The basis vectors are called the \emph{generators}\index{generators} of the Lie algebra.

Write their Lie brackets as
\[
	[T_a, T_b] = f\indices{^{c}_{ab}} T_c,
\]
with $f\indices{^{c}_{ab}} \in \mathbb{F}$ called the \emph{structure constants}\index{structure constants}. The properties imply:
\begin{itemize}
	\item antisymmetry $\implies f\indices{^{c}_{ba}} = - f\indices{^{c}_{ab}}$.
	\item Jacobi $\implies f\indices{^{e}_{ad}} f\indices{^{d}_{bc}} + f\indices{^{e}_{cd}} f\indices{^{d}_{ab}} + f\indices{^{e}_{bd}} f\indices{^{d}_{ca}} = 0$.
\end{itemize}

General elements of Lie algebras are linear combinations of $\{T_a\}$. So $X \in V$ can be written as $X^a T_a$, where $X^a \in \mathbb{F}$, and
\[
	[X, Y] = X^a Y^b f\indices{^{c}_{ab}} T_c.
\]

\subsection{Lie Groups and their Lie Algebras}%
\label{sub:lg_la}

We start with $\mathsf{SO}(2)$, where
\[
g(\theta) =
\begin{pmatrix}
	\cos \theta & -\sin \theta \\
	\sin \theta & \cos \theta
\end{pmatrix}.
\]
The identity is $e = I_2 = g(0)$. Near the identity, $\theta$ is small, and
\[
\sin \theta = \theta - \frac{\theta^3}{3} + \cdots, \qquad \cos \theta = 1 - \frac{\theta^2}{2} + \cdots
\]
Hence,
\[
g(\theta) = I_2 + \theta
\begin{pmatrix}
	0 & -1 \\ 1 & 0
\end{pmatrix} - \frac{\theta^2}{2} I_2 + \mathcal{O}(\theta^3) = e + \theta \frac{\diff g}{\diff \theta} \biggr|_{0} + \mathcal{O}(\theta^2).
\]
The linear term is the ``tangent'' to the manifold. We have a one-dimensional tangent space at $e$, and we claim that this is the Lie algebra of $\mathsf{SO}(2)$, i.e.
\[
L(\mathsf{SO}(2)) = T_e(\mathsf{SO}(2)) = \left\{
	\begin{pmatrix}
		0 & -a \\ a & 0
	\end{pmatrix}
\biggm| a \in \mathbb{R} \right\}.
\]

For $\mathsf{SO}(n)$, we can show the dimension is $\frac{n(n-1)}{2} = d$. Choose coordinates $x_1, \ldots, x_d$, and consider a single-parameter family of $\mathsf{SO}(n)$ elements
\[
M(t) = M(x(t)) \in \mathsf{SO}(n),
\]
such that $M(0) = I_n$. Then,
\[
0 = \frac{\diff}{\diff t} (M^T(t) M(t)) = \frac{\diff M^T}{\diff t} M + M^T \frac{\diff M}{\diff t}.
\]
Looking at $t = 0$, we find
\[
\frac{\diff M^T}{\diff t} = - \frac{\diff M}{\diff t},
\]
hence matrices in the tangent space are anti-symmetric. Moreover they are also traceless.

% lecture 4

For unitary groups, we again let $M(t)$ be a curve in $\mathsf{SU}(n)$ with $M(0) = I$. For small $t$, write
\[
M(t) = I + t X + \mathcal{O}(t^2).
\]
From unitarity, $I = M^{\dagger} M$, so looking at the expansion,
\[
I = I + t(X + X^\dagger) + \mathcal{O}(t^2),
\]
hence $X^\dagger = -X$, is anti-hermitian. We also claim $X$ is traceless for $\mathsf{SU}(n)$. Indeed, looking at $\det M$, its expansion is
\[
1 = \det M = 1 + t \Tr(X) + \mathcal{O}(t^2).
\]
\subsection{Lie Algebras of a Matrix Lie Group}%
\label{sub:la_mlg}

Consider two curves through the identity $e$ of some Lie group, $g_1(x(t))$ and $g_2(y(t))$, with $X_1 = \dot g_1|_0$, $X_2 = \dot g_2|_0$. The product is
\[
g_3(z(t)) = g_2(y(t)) g_1(x(t)) \in G.
\]
Then,
\[
\dot g_3|_0 = (\dot g_1 g_2 + g_1 \dot g_2)|_0 = X_1 + X_2 \in T_e(G).
\]
The Lie bracket arises from the group commutator.

\begin{definition}
	The \emph{group commutator}\index{group commutator} of $g_1, g_2 \in G$ is
	\[
		[g_1, g_2] = g_1^{-1} g_2^{-1} g_1 g_2 \in G.
	\]
\end{definition}

Let $g_1(t), g_2(t)$ be two curves through the identity, and
\[
g_i(t) = c + t X_i + t^2 W_i + \mathcal{O}(t^3).
\]
Then,
\begin{align*}
	g_1(t) g_2(t) &= e + t(X_1 + X_2) + t^2(X_1 X_2 + W_1 + W_2) + \mathcal{O}(t^3), \\
	g_2(t) g_1(t) &= e + t(X_1 + X_2) + t^2(X_2 X_1 + W_1 + W_2) + \mathcal{O}(t^3).
\end{align*}
Therefore,
\[
	h(t) = [g_2(t)g_1(t)]^{-1} g_1(t) g_2(t) = e + t^2[X_1, X_2] + \cdots.
\]
So if $h(t) \in G$, then the tangent to $h(t)$ at $e$ is $[X_1, X_2] \in L(G)$.

Now we can think of tangent spaces to $G \subseteq \mathsf{GL}(n, \mathbb{F})$ at a general element $p$, $T_p(G)$.

Let $g(t)$ be a curve in the manifold through $p$ with $g(t_0) = p$, so
\[
g(t_0 + \eps) = g(t_0) + \eps \dot g (t_0) + \mathcal{O}(\eps^2).
\]
Both $g(t_0)$ and $g(t_0 + \eps)$ are in $G$, so there exists $h_p(\eps) \in G$ such that
\[
g(t_0 + \eps) = g(t_0) h_p(\eps),
\]
where $h_p(0) = e$. For small $\eps$,
\[
h_p(\eps) = e + \eps X_p + \mathcal{O}(\eps^2)
\]
for some $X_p \in L(G) = T_e(G)$. Neglecting higher order terms,
\begin{align*}
	e + \eps X_p &= h_p(\eps) = g(h_0)^{-1} g(t_0 + \eps) \\
		     &= g(t_0)^{-1} [g(t_0) + \eps \dot g (t_0)] \\
		     &= e + \eps g(t_0)^{-1} \dot g(t_0),
\end{align*}
where $g(t)^{-1} \dot g(t) = X_p \in L(G)$.

Conversely, for any $X \in L(G)$, there exists a unique curve $g(t)$ with $g^{-1}(t) \dot g(t) = X$, and $g(0) = g_0$. This is a consequence of the existence and uniqueness of solutions to ODEs. The solution of this ODE is
\[
g(t) = g_0 \exp tX,
\]
where
\[
\exp tX = \sum_{k = 0}^\infty \frac{1}{k!} (tX)^k.
\]
Given an $X \in L(G)$, the curve
\[
g_X(t) = \exp tX,
\]
which forms an abelian subgroup of $G$ generated by $X$. Note $g_x(t)$ is isomorphic to $(\mathbb{R}, +)$ if only $g_x(0)=  e$, and $S^1$ if $g_x(t_0) = e$ for some $t_0 \neq 0$.

% lecture 5

\subsection{Lie Groups from Lie Algebras}%
\label{sub:lg_la}

Given a Lie algebra $L(G)$ of a Lie group $G$, we can define the \emph{exponential map}\index{exponential map}
\[
\exp : L(G) \to G.
\]
For matrix Lie groups,
\[
X \mapsto \exp X = \sum_{k = 0}^\infty \frac{X^k}{k!}.
\]
Locally, the map is bijective, but globally it may not be.
\begin{exbox}
	Recall the group
	\[
		\mathsf{U}(1) = \{ e^{i\theta} \mid \theta \in [0, 2\pi)\}.
	\]
	The Lie algebra is
	\[
		L(\mathsf{U}(1)) = \{ ix \mid x \in \mathbb{R}\}.
	\]
	The exponential is not one-to-one, since $e^{2 \pi n i} = 1$.

	Another example is $G = \mathsf{O}(n)$. Let $X \in L(O(n)) \in \mathrm{Skew}_n(\mathbb{R})$.

	Let $M = \exp t X$, then
	\[
		M^T = [\exp tX]^T = \exp(-t X),
	\]
	so $MM^T = I = M^T M$, hence $M \in O(n)$.

	Suppose that $\Tr X = 0$. Let $\lambda_1, \ldots, \lambda_n$ be the eigenvalues. Then,
	\[
	\det M = \det (\exp t X) = \exp(t(\lambda_1 + \cdots + \lambda_n)) = \exp (t \Tr X) = 1.
	\]
	So $M \in \mathsf{SO}(n)$. Thus elements of $\mathsf{O}(n)$ with determinant $-1$ are not in the image of the $\exp$ map. We can think of $\mathsf{O}(n)$ as a disconnected manifold.
\end{exbox}

We can show that if $A \in \mathrm{Skew}_n(\mathbb{R})$, then $A \in L(\mathsf{SO}(n))$ or $L(\mathsf{O}(n))$.

Define $\gamma(t) = \exp t A$, a curve of matrices on some manifold. From the above,
\[
	(\gamma(t))^T(\gamma(t)) = I, \qquad \det \gamma(t) = 1,
\]
so $\gamma(t) \in \mathsf{SO}(n)$. By construction, $A = \gamma(t)|_0$, the tangent to the curve at the identity. So $A \in L(\mathsf{SO}(n))$, hence
\[
\dim \mathrm{SO}(n) = \dim L(\mathrm{SO}(n)) = \dim \mathrm{Skew}_n(\mathbb{R}) = \frac{n(n-1)}{2}.
\]
We can also determine the group product from the Lie bracket.
\begin{lemma}[Baker-Campbell-Hausdorff Formula]
	For $X, Y \in L(G)$, we have $\exp tX \exp tY = \exp tZ$, where
	\[
		Z = X + Y + \frac{t}{2}[X, Y] + \frac{t^2}{12}([X, [X, Y]] + [Y, [X, Y]]) + \mathcal{O}(t^3).
	\]
\end{lemma}

We can show this order-by-order in $t$.  Since $L(G)$ is closed under the Lie bracket, $Z \in L(G)$, so $\exp t Z \in G$.

\newpage

\section{Representations}%
\label{sec:rep}

Groups are transformations under which some things are invariant.

Representations are how group actions transform vectors in a vector space.

An example is $\mathsf{GL}(n, \mathbb{F})$, the group of invertible matrices. These form linear maps (automorphisms) on the vector space $\mathbb{F}^n$.

\subsection{Lie Group Representations}%
\label{sub:lie_rep}

\begin{definition}
	A \emph{representation}\index{representation} $D$ of a group $G$ is a smooth group homomorphism
	\[
	D : G \to \mathsf{GL}(V),
	\]
	from $G$ to the group of automorphisms on some vector space $V$, called the \emph{representation space}\index{representation space} associated with $D$.

	That is, for all $g \in G$, $D(g) : V \to V$ is an invertible, linear map such that for a vector $v \in V$,
	\[
	v \mapsto D(g) v.
	\]
	\begin{itemize}
		\item Linearity: $D(g)(\alpha v_1 + \beta v_2) = \alpha D(g) v_1 + \beta D(g) v_2$.
		\item Group structure: $D(g_2 g_1) = D(g_2) D(g_1)$.
		\item Identity: $D(0) = \id_V$.
		\item Inverses: $D(g)^{-1} = D(g^{-1})$.
	\end{itemize}
\end{definition}

\begin{definition}
	The \emph{dimension}\index{dimension} of a representation $D$ is the dimension of its vector space. If $V$ is finite-dimensional, say $\dim V = N$, then $\mathsf{GL}(V)$ is isomorphic to $\mathsf{GL}(N, \mathbb{F})$.
\end{definition}

% lecture 6

Recall that the kernel of a map $D : G \to \mathsf{GL}(V)$ consists of the elements of $G$ which map to the identity $\id_V$.

\begin{definition}
	A representation $D$ is \emph{faithful}\index{faithful} if $D(g) = \id_V$, only for $g = e$, i.e. $\ker D = \{e\}$.
\end{definition}

Faithfulness implies that $D$ is injective.

\begin{exbox}
	We look at some examples with $G = (\mathbb{R}, +)$.
	\begin{enumerate}[(i)]
		\item For some fixed $k \in \mathbb{R}$, $D(x) = e^{k \alpha}$ is a one-dimensional representation, as
			\[
			D(\alpha) D(\beta) = e^{k \alpha} e^{k \beta} = e^{k(\alpha + \beta)} = D(\alpha + \beta).
			\]
			For $k \neq 0$, this is faithful, as $D(\alpha) = 1 \implies \alpha = 0$. For $k = 0$, $D(\alpha) = 1$ for all $\alpha$, so $\ker D = G$. This is the trivial representation.
		\item Another one-dimensional representation is $D(\alpha) = e^{ik\alpha}$. This is again not faithful.
		\item A two-dimensional representation is
			\[
			D(\alpha) =
			\begin{pmatrix}
				\cos \alpha & - \sin \alpha \\
				\sin \alpha & \cos \alpha
			\end{pmatrix}.
			\]
		\item Let $V$ be the space of all functions, and define
			\[
			D(\alpha) f(x) = f(x - \alpha).
			\]
			This is an infinite-dimensional representation, which is faithful, as $f(x) = f(x - \alpha)$ for all $f$ implies $\alpha = 0$.		
	\end{enumerate}
\end{exbox}

\begin{definition}
	The \emph{trivial representation}\index{trivial representation} $D_0$ is where
	\[
	D_0(g) = 1,
	\]
	for all $g \in G$.
\end{definition}

Quantities which are invariant under group transformation transform in the trivial representation.

We can also form a trivial representation for any dimension, by $D(g) = I_m$ for all $g$. This is reducible; it is $M$ copies of the one-dimensional trivial representation.

\begin{definition}
	If $G$ is a matrix Lie group, then the \emph{fundamental}\index{fundamental} or \emph{defining representation}\index{defining representation} $D_f$ is given by
	\[
	D_f(g) = g,
	\]
	for all $g \in G$.
\end{definition}

This is clearly faithful, and if $G \subseteq \mathsf{GL}(n, \mathbb{F})$, then $\dim D_f = n$.

Let $G$ be a matrix Lie group and consider its Lie algebra as a vector space $V = L(G)$.

\begin{definition}
	The \emph{adjoint representation}\index{adjoint representation} $D^{\mathrm{adj}} = \mathrm{Ad}$ is the map $\mathrm{Ad} : G \to \mathsf{GL}(L(G))$ such that for all $g \in G$, $\mathrm{Ad}_g : L(G) \to L(G)$ by
	\[
	\mathrm{Ad}_g X = g X g^{-1}
	\]
	for all $X \in L(G)$. This is just action by conjugation.
\end{definition}

We can check that this satisfies the group operations, and the Lie bracket satisfies
\[
	\mathrm{Ad}_g([X, Y]) = g[X, Y]g^{-1} = [gXg^{-1}, gYg^{-1}] = [\mathrm{Ad}_g X, \mathrm{Ad}_g Y].
\]

\subsection{Lie Algebra Representation}%
\label{sub:lar}

\begin{definition}
	A \emph{representation}\index{representation} $d$ of a Lie algebra $L(G)$ is a linear map from $L(G)$ to $\mathfrak{gl}(V)$, which is the Lie algebra of $\mathsf{GL}(V)$, that preserves the Lie bracket.

	That is, for each $X \in L(G)$, $d(X) : V \to V$ is a linear map such that
	\[
	v \mapsto d(X) v,
	\]
	for $v \in V$, such that
	\[
		d([X, Y]) = [d(X), d(Y)].
	\]
	The dimension of this $d$ is then $\dim V$.
\end{definition}

% lecture 7

\begin{definition}
The trivial representation is
\[
d_0(X) = 0.
\]
\end{definition}

\begin{definition}
The fundamental representation is
\[
d_f(X) = X.
\]
\end{definition}

\begin{definition}
The adjoint representation is
\[
\mathrm{ad} : L(G) \to \mathfrak{gl}(L(G)),
\]
such that for all $X \in L(G)$, $\mathrm{ad}_X : L(G) \to L(G)$ such that
\[
	\mathrm{ad}_X Y = [X, Y].
\]
\end{definition}

We can get representations of $L(G)$ from representations of $G$.

As before, consider the tangent cuves in $G$:
\[
g(t) = e + t X + \cdots.
\]
Expand corresponding elements of our representation $D$ of $G$ as
\[
D(g(t)) = \id_V + t d (X) + \cdots.
\]
Then we can use this expansion to define $d$ from $D$. We can check the Lie bracket works. We know
\[
D(g_1^{-1} g_2^{-1} g_1 g_2) = D(g_1)^{-1} D(g_2)^{-1} D(g_1) D(g_2).
\]
Expanding $g_1(t) = e + T X_1 + \cdots$, $g_2(t) = e + t X_2 + \cdots$, we find the left-hand side gives
\[
	D(e + t^2[X_1, X_2] + \cdots),
\]
and the right-hand side is
\[
	\id_V + t^2[d(X_1), d(X_2)] + \cdots.
\]
Hence we see that
\[
	d([X_1, X_2]) = [d(X_1), d(X_2)].
\]
For example, in the adjoint representation $\mathrm{ad}_X$ from $\mathrm{Ad}_g$, for $Y \in L(G)$ note
\begin{align*}
	\mathrm{Ad}_g Y &= g Y g^{-1} = (I + tX) Y(I - tX) + \cdots \\
			&= Y + t[X, Y] + \cdots \\
			&= (I + t \mathrm{ad}_X + \mathcal{O}(t^2)) Y.
\end{align*}
So $\mathrm{ad}_X Y = [X, Y]$.

\subsection{Useful Concepts}%
\label{sub:use}

\begin{definition}
	Representations $D_1$ and $D_2$ of $G$, or $d_1$ and $d_2$ of $L(G)$, are \emph{equivalent}\index{equivalent} if there exists invertible linear maps $R$ and $S$ such that
	\begin{align*}
		D_2(g) &= R D_1(g) R^{-1}, \\
		d_2(X) &= S d_1(X) S^{-1},
	\end{align*}
	for all $g \in G$ or $X \in L(G)$.
\end{definition}

\begin{definition}
	A representation $d$ of $L(G)$ with representation space $V$ has an \emph{invariant subspace}\index{invariant subspace} $W \subseteq V$ if $d(X) w \in W$, for all $X \in L(G)$ and $w \in W$.
\end{definition}

\begin{exbox}
	If all $d(X)$ are upper-triangular matrices, then $W = \{(z, 0)^{T}\}$ are invariant.
\end{exbox}

\begin{definition}
	An \emph{irreducible representation}\index{irreducible representation} (irrep) is a representation with no nontrivial invariant subspaces. Otherwise the representation is \emph{reducible}\index{reducible}.
\end{definition}

\begin{definition}
	A \emph{direct sum}\index{direct sum} of vector spaces $U$ and $W$, is
	\[
		U \oplus W = \{(u, w) \text{ or } u \oplus w \mid u \in U, w \in W\},
	\]
	where $(u_1, w_1) + (u_2, w_2) = (u_1 + u_2, w_1 + w_2)$ and $\alpha(u, w) = (\alpha u, \alpha w)$. Note that
	\[
	\dim U \oplus W = \dim U + \dim W.
	\]
\end{definition}

\begin{definition}
	A \emph{totally reducible representation}\index{totally reducible representation} $d$ of $L(G)$ can be decomposed into irreducible pieces, i.e. can be written as a direct sum with representation space
	\[
	V = W_1 \oplus W_2 \oplus \cdots \oplus W_k,
	\]
	such that $d(X) w_i \in W_i$ for all $X \in L(G)$. Then there exists some basis where
	\[
	d(X) =
	\begin{pmatrix}
		d_1(X) & 0 & \cdots & 0 \\
		0 & d_2(X) & \cdots & 0 \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots & d_n(X)
	\end{pmatrix}
	\]
	is a block diagonal.
\end{definition}

\begin{definition}
	An $N$-dimensional representation $D$ is \emph{unitary}\index{unitary theorem} if $D(g) \in \mathsf{U}(N)$, and $d(X) \in L(\mathsf{U}(N))$.

	If all $D(g)$ are real, then $D(g) \in \mathsf{O}(N)$, and $D$ is said to be \emph{orthogonal}\index{orthogonal representation}.
\end{definition}

\begin{theorem}[Maschke]
	A finite-dimensional unitary representation is either irreducible, or totally reducible.
\end{theorem}

\begin{proofbox}
	Sketch.

	We show that for each invariant subspace $W$, the orthogonal component $W_{\perp}$ is also invariant, i.e. $V = \oplus W + W_{\perp}$.

	Then we can similarly decompose $W$ and $W_{\perp}$. As $V$ is finite dimensional, we must terminate.
\end{proofbox}

Maschke's theorem can be extended to:
\begin{itemize}
	\item All finite representations of discrete groups (by Weyl's trick).
	\item All finite representations of compact Lie groups.
\end{itemize}

\begin{exbox}
	Consider $V$ to be all $2\pi$-periodic functions, and a representation by
	\[
	D(\alpha) f(x) = f(x - \alpha).
	\]
% lecture 8
	The following subspaces are invariant:
	\[
		W_n = \{a_n \cos n x + b_n \sin nx \mid a_n, b_n \in \mathbb{R} \},
	\]
	for each $n \in \mathbb{Z}_{\geq 0}$. This is invariant as
	\[
	a_n \cos n(x - \alpha) + b_n \sin n(x - \alpha) = a_n' \cos nx + b_n' \sin nx
	\]
	for some $a_n', b_n' \in \mathbb{R}$.

	Recall the Fourier decomposition of any $2\pi$-periodic function: it can be written as
	\[
	f(x) = a_0 + \sum_{n = 1}^\infty (a_n \cos nx + b_n \sin nx).
	\]
	Hence we see
	\[
	V = W_0 \oplus W_1 + W_2 \oplus \cdots = \oplus_{n = 0}^{\infty} W_n.
	\]
	This is a direct sum of covariant derivatives, each occurring once.
\end{exbox}

\begin{definition}
	Let $V, W$ be vector spaces. The \emph{tensor product space}\index{tensor product space} $V \otimes W$ is spanned by elements, which are product vectors $v \otimes w$ with $v \in V$, $w \in W$. Here,
	\[
	v \otimes (\lambda_1 w_1 + \lambda_2 w_2) = \lambda_ v \otimes w_1  + \lambda_2 v \otimes w_2.
	\]
	Hence, $\dim V \otimes W = (\dim V)(\dim W)$.

	An element is in a \emph{product state}\index{product state} if it can be written $\phi = v\otimes w$. In general we can write $\phi_A = \phi_{a\alpha} = v_a w_\alpha$.

	Not all elements of $V \otimes W$ are product states.
\end{definition}

\subsection{Tensor Products Representations}%
\label{sub:tpr}

Let $D^{(1)}$ and $D^{(2)}$ be representations of a group $G$ with vector spaces $V$ and $W$ such that
\begin{align*}
	D^{(1)}(g) : v_\alpha &\mapsto D^{(1)}(g)_{\alpha\beta} v_\beta, \\
	D^{(2)}(g) : w_\alpha &\mapsto D^{(2)}(g)_{\alpha\beta} w_\beta.
\end{align*}
Then we get a tensor product representation $D^{(1)j \otimes D^{(2)}}$, by
\[
	(D^{(1)} \otimes D^{(2)})(g) (v \otimes w) = (D^{(1)}(g) v ) \otimes (D^{(2)}(g) w).
\]
Let $g_t \in G$ be a curve in the Lie group $G$ with $g_0 = e$, and $\dot g_0 = X \in L(G)$. Then,
\begin{align*}
	\frac{\diff}{\diff t} \left[ (D^{(1)} \otimes D^{(2)})(g_t) v \otimes w \right] &= \left[ \frac{\diff}{\diff t} D^{(1)}(g_t) v \right] \otimes w + v \otimes \left[\frac{\diff}{\diff t} D(g_t) w \right].
\end{align*}
Let $d^{(1)}$ and $d^{(2)}$ be Lie algebra representations corresponding to $D^{(1)}$ and $D^{(2)}$. Their tensor product is
\[
	(d^{(1)} \otimes d^{(2)})(X) = d^{(1)}(X) \otimes \id_W + \id_V \otimes d^{(2)}(X).
\]

Here is an important corollary to Maschke's theorem: representations of $d^{(1)} \otimes d^{(2)}$ can be, if finite, written as the direct sum of irreps of $L(G)$:
\[
d^{(1)} \otimes d^{(2)} = \tilde d_1 \oplus \cdots \oplus \tilde d_k = \bigoplus_{i = 1}^k \tilde d_i.
\]
This is decomposition into irreps. Note that the dimensions must be equal.

\newpage

\section{Angular Momentum}%
\label{sec:am}

$\mathsf{SO}(3)$ describes rotations in three-dimensions. This implies that angular momentum is quantized in QM.

Sometimes we have half integer quantum numbers, which gives $\mathsf{SU}(2)$ representations.

\subsection{Relationships between \texorpdfstring{$\mathsf{SO}(3)$}{SO(3)} and \texorpdfstring{$ \mathsf{SU}(2)$}{SU(2)}}%
\label{sub:rels}

Consider the Lie algebra of $\mathsf{SU}(2)$, the $2 \times 2$ traceless, anti-Hermitian matrices. We can choose a basis
\[
T_a = - \frac{i}{2} \sigma_a,
\]
for $a = 1, 2, 3$. These are the \emph{Pauli matrices}\index{Pauli matrices}. Recall that
\[
	\sigma_a \sigma_b = I \delta_{ab} + i \eps_{abc} \sigma_c \implies [T_a, T_b] = \eps_{abc} T_c.
\]
Hence the structure constants are
\[
f\indices{^{c}_{ab}} = \eps_{abc}.
\]
Similarly, $\mathfrak{so}(3) = L(\mathsf{SO}(3))$ are the $3 \times 3$ skew matrices, with basis
\[
\tilde T_1 =
\begin{pmatrix}
	0 & 0 & 0 \\
	0 & 0 & -1 \\
	0 & 1 & 0
\end{pmatrix},
\qquad \tilde T_2 =
\begin{pmatrix}
	0 & 0 & 1 \\
	0 & 0 & 0 \\
	-1 & 0 & 0
\end{pmatrix},
\qquad
\tilde T_3 =
\begin{pmatrix}
	0 & -1 & 0 \\
	1 & 0 & 0 \\
	0 & 0 & 0
\end{pmatrix}.
\]
i.e. $(\tilde T_a)_{bc} = - \eps_{abc}$. Then again
\[
	[\tilde T_a, \tilde T_b] = \eps_{abc} \tilde T_c,
\]
which gives the same structure constants as $\mathfrak{su}(2)$.

To show an isomorphism between two Lie algebras $\mathfrak{g}$ and $\mathfrak{h}$, we need a linear isomorphism $\phi : \mathfrak{g} \to \mathfrak{h}$ such that
\[
	\phi([X, Y]) = [\phi(X), \phi(Y)],
\]
for all $X, Y \in \mathfrak{g}$. However, we find that $\mathfrak{su}(2)$ and $\mathfrak{so}(3)$ are not isomorphic.

Let's look at the group manifolds of the Lie groups.
\begin{itemize}
	\item $\mathsf{SO}(3)$ was discussed earlier. This can be thought of as a $3$-ball of radius $\pi$, with antipodes identified.
	\item $\mathsf{SU}(2)$ can be written as
		\[
		U = a_0 \cdot I + i \mathbf{a} \cdot \bm{\sigma},
		\]
		with $(a_0, \mathbf{a})$ real and $a_0^2 + |\mathbf{a}|^2 = 1$. This manifold is a unit sphere in $\mathbb{R}^4$, i.e. $S^3$.
\end{itemize}

\begin{definition}
	Let $H$ be a subgroup of $G$. Then for any $g \in G$, we can form a \emph{left coset}\index{left coset} of $H$ as
	\[
		gH = \{gh \mid h \in H\},
	\]
	and the \emph{right coset}\index{right coset} as
	\[
		Hg = \{hg \mid h \in H\}.
	\]
\end{definition}

\begin{definition}
	$H \lhd G$ is a \emph{normal subgroup}\index{normal subgroup} of $G$, if $gH = Hg$ for all $g \in G$. Define a set $G/H$ to be
	\[
		G/H = \{g H \mid g \in G\}.
	\]
	Define coset multiplication as
	\[
		(g_2 H)(g_1 H) = (g_2 g_1)H.
	\]
\end{definition}

\begin{theorem}
	For $H \lhd G$, $G/H$ is a group under coset multiplication, with $H = eH$ as the identity of $G/H$. Such a group is called the \emph{quotient group}\index{quotient group}.
\end{theorem}

% lecture 9

\begin{definition}
	The \emph{centre}\index{centre} of a group is the set of all $x \in G$ which satisfy $xg = gx$ for all $g \in X$.
\end{definition}

\begin{theorem}
	The centre $Z(G) \lhd G$ is a normal subgroup of $G$.
\end{theorem}

$\mathsf{SU}(2)$ has centre $Z(\mathsf{SU}(2)) = \{\pm I\}$. The cosets are
\[
	U Z(\mathsf{SU}(2)) = \{\pm U\}.
\]
The set of all such cosets forms the quotient group
\[
\mathsf{SU}(2) / \mathbb{Z}_2,
\]
whose manifold is $S^3$ with antipodes identified. The manifold of $\mathsf{SU}(2) / \mathbb{Z}_2$ is just the upper half of $S^3$, with opposite points on the equator identified. However this can be projected onto $\mathsf{SO}(3)$, showing
\[
\mathsf{SO}(3) \cong \mathsf{SU}(2) / \mathbb{Z}_2.
\]
We are able to show an explicit map. Define $p : \mathsf{SU}(2) \to \mathsf{SO}(3)$ by, for $A \in \mathsf{SU}(2)$, $p(A) = R$ where
\[
R_{ij} = \frac{1}{2} \tr(\sigma_i A \sigma_j A^{\dagger}).
\]
This is a two-to-one map, with $p(-A) = p(A)$. This is a \emph{double cover}\index{double cover} of $\mathsf{SO}(3)$. Hence $\mathsf{SU}(2)$ is the double cover of $\mathsf{SO}(3)$.

\begin{proposition}
	Every Lie algebra is the algebra of exactly one simply-connected Lie group.
\end{proposition}

For example, $\mathsf{U}(2)$ and $\mathsf{SU}(2)$ have the same Lie algebra, but $\mathsf{U}(2)$ is not connected.

\begin{definition}
	A manifold is \emph{simply connected}\index{simply connected} if any closed loop can be smoothly shrunk to a point, i.e. $\pi_1(X)$ is trivial.
\end{definition}

\subsection{Representations of \texorpdfstring{$\mathfrak{su}(2)$}{su(2)}}%
\label{sub:rep_su2}

It is convenient to enlarge our real vector space to the field $\mathbb{C}$. Given a vector space $V$, say
\[
	V = \{\lambda^a T_a \mid \lambda^a \in \mathbb{R}\} = \spn_{\mathbb{R}} \{T_a\}.
\]
The \emph{complexification}\index{complexification} of $V$ is
\[
	V_{\mathbb{C}} = \spn_{\mathbb{C}}\{T_a\}.
\]

\begin{exbox}
	Recall
	\[
		\mathfrak{su}(n) = \{X \in \mathrm{Mat}_n(\mathbb{C}) \mid X^{\dagger} = -X, \Tr X = 0\}.
	\]
	Then the complexification is
	\[
		\mathfrak{su}(n)_{\mathbb{C}} = \{X \in \mathrm{Mat}_n(\mathbb{C}) \mid \Tr X = 0\} \cong \mathfrak{sl}(n, \mathbb{C}) = L(\mathsf{SL}(n, \mathbb{C})).
	\]
\end{exbox}

Let $\mathfrak{g} = L(G)$ be a real Lie algebra, and denote its complexification by $\mathfrak{g}_{\mathbb{C}}$. Representations of $L(G)$ can be extended to $L(G)_{\mathbb{C}}$ by imposing
\[
d(X+ iY) = d(X) + i d(Y).
\]
Conversely, if we have a representation $d_{\mathbb{C}}$ of $L(G)_{\mathbb{C}}$, we can restrict to a representation of $L(G)$ by writing
\[
d(X) = d_{\mathbb{C}}(X)
\]
for $X \in L(G) \subseteq L(G)_{\mathbb{C}}$.

\begin{definition}
	A \emph{real form}\index{real form} of a complex Lie algebra $\mathfrak{h}$ is a real Lie algebra $\mathfrak{g}$ whose complexification is $\mathfrak{h}$.
\end{definition}

In general, a complex Lie algebra can have multiple nonisomorphic real forms. For $L(\mathsf{SU}(2))$,
\[
L(\mathsf{SU}(2))_{\mathbb{C}} = \spn_{\mathbb{C}} \{\sigma_a \mid a = 1, 2, 3\}.
\]
A more conveniant basis is
\begin{align*}
	H &= \sigma_3 =
	\begin{pmatrix}
		1 & 0 \\ 0 & -1
	\end{pmatrix}
	, \\
	E_+ &= \frac{1}{2}(\sigma_1 + i \sigma_2) =
	\begin{pmatrix}
		0 & 1 \\ 0 & 0
	\end{pmatrix}, \\
	E_{-} &= \frac{1}{2}(\sigma_1 - i \sigma_2) =
	\begin{pmatrix}
		0 & 0 \\ 1 & 0
	\end{pmatrix}.
\end{align*}
Then the commutation relations are
\[
	[H, E_{\pm}] = \pm 2 E\pm, \qquad [E_+, E_-] = H.
\]
This is the Canton-Weyl basis.

Recall that $\mathrm{ad}_X Y = [X, Y]$, so $[H, E_{\pm}] = \mathrm{ad}_H E_{\pm} = \pm 2 E_{\pm}$. We also have that $\mathrm{ad}_H H = [H, H] = 0$.

We see that $E_-, H, E_+$ are eigenvectors of $\mathrm{ad}_H$ with eigenvalues $-2, 0, 2$. These eigenvalues are the \emph{roots}\index{roots} of $L(\mathsf{SU}(2))$.

Let $d$ be a finite dimensional irreducible representation (an irrep) of $\mathsf{SU}(2)$ with representation space $V$. Write an eigenvector of $d(H)$ as $v_\lambda$, where
\[
d(H) v_\lambda = \lambda v_\lambda.
\]

\begin{definition}
	The eigenvectors of $d(H)$ are the \emph{weights}\index{weights} of $d$.
\end{definition}

The operators $d(E_{\pm})$ are \emph{ladder}\index{ladder} or \emph{step}\index{step} or \emph{raising}\index{raising} or \emph{lowering}\index{lowering} operators, as
\[
d(H) (d(E_{\pm})v_\lambda) = (\lambda \pm 2)(d(E_{\pm}) v_\lambda).
\]
Hence $d(E_{\pm})v_\lambda$ is an eigenvector of $d(H)$ with eigenvalue $\lambda \pm 2$, or $d(E_{\pm}) v_\lambda = 0$.


% lecture 10

If $d$ is a finite dimensional representation, then there is a finite number of eigenvalues. Hence there must be some $\Lambda$ such that
\[
	d(H) v_\Lambda = \Lambda v_\Lambda \qquad \text{and} \qquad d(E_+) v_\Lambda = 0.
\]
Such a $\Lambda$ is called a \emph{highest weight}\index{highest weight}. Applying $d(E_-)$ $n$ times,
\[
v_{\Lambda - 2n} = (d(E_-))^{n} v_\Lambda.
\]
This process must terminate for some $N$, so the eigenbasis for this representation is

% lecture 11

\newpage

\printindex

\end{document}
