\documentclass[12pt]{article}

\usepackage{ishn}

\makeindex[intoc]

\begin{document}

\hypersetup{pageanchor=false}
\begin{titlepage}
	\begin{center}
		\vspace*{1em}
		\Huge
		\textbf{III Analysis of PDEs}

		\vspace{1em}
		\large
		Ishan Nath, Michaelmas 2024

		\vspace{1.5em}

		\Large

		Based on Lectures by Prof. Cl\'ement Mouhot

		\vspace{1em}

		\large
		\today
	\end{center}
	
\end{titlepage}
\hypersetup{pageanchor=true}

\tableofcontents

\newpage

% lecture 1

\setcounter{section}{-1}

\section{Introduction}%
\label{sec:intro}

Email cm612, in E1.12. Notes are on wordpress, or by Warnick typed by Minter.

Books include Evans, Br\'ezis, John and Lieb-Loss.

\subsection{Overview}%
\label{sub:over}

The field proceeds from works on differential calculus, and trying to turn laws of physics into equations.

We are focused on the modern approach: finding estimates, limits and the function space (using topology). We are not looking at finding explicit formulas.

The course is structured as follows.
\begin{enumerate}[label=Chapter \arabic*.]
	\item Introduction (2 lectures). This is focused on turning an ODE into a PDE.
	\item The Cauchy Kovalevskoya Theory (4-5 lectures). Here we look at a PDE with analytic function, where we want to solve for analytic solutions. This lets us construct locally a solution.
	\item Functional toolbox (4 lectures). Here we introduce H\"older and Lebesgue spaces, as well as weak derivatives, Sobolev spaces, inequalities, approximations by convolution, and extensions or traces of functions.
	\item Elliptic PDEs (6-7 lectures). Here we look at the Laplace equation and its variants $\Delta u = 0$ on $U$, and $u |_{\partial U} = g$. We are most interested in Lax-Milgram theory, and may look at Fredholm theory, and spectral theory.
	\item Hyperbolic PDEs (7 lectures). The main equations are the scalar transport equation (where we look at the Burgers equation), and the wave equation.
\end{enumerate}

\newpage

\section{From ODEs to PDEs}%
\label{sec:ode2pde}

In \emph{differential equations}\index{differential equation}, the unknown is a function. In an ODE (ordinary differential equation), we first fix a function
\[
F = F(x, y_1, \ldots, y_{k+1}).
\]
Here $k \geq 1$. We solve for $u : U \subseteq \mathbb{R} \to \mathbb{R}$ the relation, for all $x \in U$,
\[
F(x, u(x), u'(x), \ldots, u^{(k)}(x)) = 0. \tag{$\ast$}
\]
Here the domain $U$ is an open, connected, regular set in $\mathbb{R}$.

\begin{exbox}
	Consider
	\[
	F = F(x, z, y) = f(x, z) - y.
	\]
	Then the equation $(\ast)$ becomes
	\[
	u'(x) = f(x, u(x)).
	\]
	This can be solved by Picard-Lindel\"of, with certain restrictions on $f$.
\end{exbox}

In a PDE, we no loner have $x$ in $\mathbb{R}$, but in $\mathbb{R}^n$. Therefore the relation $(\ast)$ must be modified to include:
\begin{align*}
	u(x) = u(x_1, \ldots, x_n), \qquad \frac{\partial u}{\partial x_i} (x), \qquad \frac{\partial^2 u}{\partial x_i \partial x_j} (x), \qquad \ldots
\end{align*}

\begin{definition}
	Give $n \geq 2$, $U \subseteq \mathbb{R}^n$ a domain, a \emph{partial differential equation}\index{partial differential equation} of rank or order $k \geq 1$ is a relation of the form, for all $x \in U$,
	\[
		F(x, u(x), Du(x), \ldots, D^k u(x)) = 0 \tag{$\ast\ast$},
	\]
	where $F : \mathbb{R}^n \times \mathbb{R} \times \mathbb{R}^n \times \mathbb{R}^{n^2} \times \cdots \times \mathbb{R}^{n^k} \to \mathbb{R}$.

	We solve for $u : U \subseteq \mathbb{R}^n \to \mathbb{R}$. If $u \in C^k(U)$, and satisfies $(\ast\ast)$ identically as an equality between continuous functions, we say that $u$ is a \emph{classical solution}\index{classical solution} to the PDE.
\end{definition}

\begin{remark}
	\begin{enumerate}[1.]
		\item[]
		\item When possible (but not for elliptic PDEs) it is useful to identify one of the components of $x$, say $x_1$, as a time $x_1 = t$. We then say that the PDE takes the form of an \emph{evolution problem}\index{evolution problem}.

			Finding such a `time variable' can be a difficulty in itself.
		\item We can also consider the more general case $u(x) \in \mathbb{R}^m$, for $m \geq 1$, and $F$ values in $\mathbb{R}^N$, for $N \geq 1$. When $m \geq 2$, we say it is a \emph{system} of PDEs.
		\item Can we consider a PDE as yet another ODE but in infinite dimensions, at least when it is in the form
			\[
			\frac{\partial u}{\partial t} = G \left( \left( \frac{\partial u}{\partial x_i} \right)_{i = 2}^n, \left( \frac{\partial^2 u}{\partial x_i \partial x_j} \right)_{i, j = 2} ^n , \ldots \right).
			\]
			No. First, losing the total order on the parameter $x$ leads to some geometric phenomena. This is repsonsible for some differences (reversibility, or whether it is an evolution problem).

Second, if we interpret this is an ODE $u'(t) = g(u)$, then $u$ lives in functional space which is infinite-dimensional, whereas in an ODE we have a trajectory in $\mathbb{R}^N$. Even at a linear level, operators can be unbounded, and the topologies are no longer equivalent.
%lecture 2
\item We also have boundary conditions. We know that just the condition $u'(t) = f(t, u(t))$ is not enough; we also need to specify, for example, $f(0) = u_0$.

	For PDEs in evolution form $\partial_t u = G$, then our boundary condition becomes $u(0, \cdot) = u_0(\cdot)$, where this is now a function. Moreover, we can consider boundary conditions on other variables.
\item Also PDEs come in so many different forms, that each structure must be understood.
	\end{enumerate}
	
\end{remark}

\begin{center}
\begin{tikzpicture}[scale=1.5]

    % Draw the cylinder (vertical)
    \draw[thick] (0,0) ellipse (1.5 and 0.5);  % Bottom ellipse (S^1)
    \draw[thick] (0,3) ellipse (1.5 and 0.5);  % Top ellipse (S^1)

    \draw[thick] (-1.5,0) -- (-1.5,3);  % Left boundary
    \draw[thick] (1.5,0) -- (1.5,3);    % Right boundary

    % Shade the bottom of the cylinder
    %\fill[gray, opacity=0.3] (-1.5,0) arc[start angle=180, end angle=0, radius=1.5 and 0.5] -- (1.5,0) -- (-1.5,0);

	% Shade the bottom ellipse (circular base of the cylinder) with gray and crosshatch
    \fill[pattern = crosshatch, pattern color=gray] (0,0) ellipse (1.5 and 0.5);

    % Boundary conditions at the base
    \node at (0,-0.8) {Boundary condition at time $t=0$};
    \node at (-1.8,0) {}; % Adjust spacing for base text

    % Boundary conditions at the boundary of the cylinder
    %\node at (2.8,1.5) {Boundary condition on boundary};

    % Time arrow
    \draw[->, thick] (2,0) -- (2,3.5) node[right] {Time};
    
    % Time progression arrow
    \node at (2,3.5) {};  % Empty node to ensure arrow placement 

\end{tikzpicture}
\end{center}

\subsection{The Cauchy Problem}%
\label{sub:cauchy}

A basic question of mathematical analysis is to solve
\[
u'(t) = F(t).
\]
If $F$ is continuous, then by FTC we get
\[
u(t) = u(t_0) + \int_{t_0}^t F(z) \diff z.
\]
This is solved. We have shown there exists solutions, and there's a unique solution given $u(t_0) = u_0$, that depends continuously on boundary data $u_0$.

A more complicated ODE is where $F = F(t, u(t))$, so
\[
u'(t) = F(t, u(t)), \qquad u(t_0) = u_0.
\]
There are three main results for functions of this form:
\begin{enumerate}[Result 1.]
	\item Cauchy-Kovalevskaya for ODEs. In the open region where $F$ is real analytic (locally the sum of a Taylor series), there exists a unique local analytic solution: given $(t_0, u_0)$ in this region, there is a neighbourhood around it so that a unique analytical solution $u$ exists.
\end{enumerate}

This has limited use: it is only for $F$ analytic, it does not cover all PDEs, and it is rare to be able to continue the solution.

We can extend this to PDEs.

\begin{enumerate}[resume*]
	\item Picard-Lindel\"of. In the region where $f'$ is continuous and Lipschitz in the second variable, there exist a local, unique solution $C^1$ solution $u$, which depends continuously on $u_0$.
\end{enumerate}

This inspired the Cauchy problem and well-posedness. We can extend this to linear PDEs, known as Hille-Yosida theorem.

\begin{enumerate}[resume*]
	\item Cauchy-Peano. In the region where $f$ is merely continuous, there exists locally a $C^1$ solution $u$. In general, it is not unique.
\end{enumerate}

This is done through an iterative scheme and compactness, and is the inspiration for theories of weak solutions in PDEs.

Note that in a larger space, existence is easier, but uniqueness is harder, and vice versa. Hence finding a sweet-spot is critical.

\begin{exbox}
	The ODE
	\[
		u'(t) = \sqrt{u(t)}, \qquad u(0) = 0
	\]
	has a solution which exists by Cauchy-Peano, but is not unique. Another example is
	\[
	u'(t) = \frac{4u(t)t}{u(t)^2 + t^2}, \qquad u(0) = 0.
	\]
\end{exbox}

Another key question is local versus global solutions, i.e. finding a global solution to
\[
u'(t) = F(t, u(t)), \qquad u(0) = u_0,
\]
for all $t \geq 0$. We have a few criterion for when global solutions exist.
\begin{enumerate}[label = Criterion \arabic*.]
	\item $F$ is uniform Lipschitz.
\end{enumerate}
Here we can just apply Picard-Lindel\"of to continue a solution. It is not easy to export this to PDEs.

\begin{enumerate}[resume*]
	\item Assume the hypothesis of Picard-Lindel\"of, as well as a growth condition on $F$:
		\[
		|F(t, u)| \leq C(1 + |u|).
		\]
		Then the solution can be continued globally.
\end{enumerate}
The idea behind this is that, a priori, a solution $C^1$ has to satisfy
\begin{align*}
	\frac{\diff}{\diff t} |u(t)|^2 &\leq 2 C (1 + |u(t)|^2), \\
	u'(t) &= F(t, u(t)).
\end{align*}
This is similar to what we call an energy estimate in PDEs.

\begin{exbox}
	The ODE
	\[
	u'(t) = u(t)^2, \qquad u(t_0) = u_0 > 0
	\]
	has no global solutions. This is because when you square a big number it gets bigger. However if we swap the sign, the solution is global. This is because when you square a small number, it gets smaller.

	The ODE
	\[
	u'(t) = \sin(u(t)), \qquad u(0) = u_0
	\]
	has global solutions, by criterion 1. Similarly,
	\[
	u'(t) = \sin (u(t)^2), \qquad u(0) = u_0
	\]
	has global solutions, this time by criterion 2.
\end{exbox}

\subsection{Well-posedness for PDEs}%
\label{sub:well_posed}

Sometimes there is no explicit formula or even series for a solution to a PDE. In these cases we need to construct solutions abstractly.

Two breakthroughs happened when looking at when PDEs have solutions. The first is the definition of a Cauchy problem, and the second is looking at well-posedness.

\begin{definition}
	A \emph{Cauchy problem}\index{Cauchy problem} is the combination of a PDE, and some boundary data; prescribing values of the unknown $u$, and possibly its derivatives, on parts of the domain.

	Such a problem is said to be \emph{well-posed}\index{well-posed} if:
	\begin{itemize}
		\item A solution exists (in some function space, e.g. $C^k(U), H^k(U)$, at least locally).
		\item The solution is unique among possible solutions in the function space.
		\item The solutions depends continuously on the boundary data.
	\end{itemize}
	
\end{definition}

% lecture 3

\subsection{Terminology and Examples}%
\label{sub:termex}

\begin{definition}
	A PDE with vector field $F$ is \emph{linear}\index{linear PDE} if $F$ is a linear function of $u$ and its derivative. So,
	\[
	\sum_{|\alpha| \leq k} a_\alpha(x) \partial^\alpha u(x) = f(x).
	\]
	Here $f(x)$ is the \emph{source}\index{source}, or the RHS.

	A PDE is \emph{semilinear}\index{semilinear} when $F$ is linear in the highest-order derivatives of $u$:
	\[
		\sum_{|\alpha| = k} a_\alpha(x) \partial^\alpha u + a_0[x, u(x), Du(x), \ldots, D^{k-1}u] = 0.
	\]
	A PDE is \emph{quasilinear}\index{quasilinear} if $F$ is linear in highest-order deriatives of $u$, but can depend nonlinearly on the lower-order derivatives:
	\[
		\sum_{|\alpha| = k} a_\alpha[x, u(x), Du(x), \ldots, D^{k-1}u] \partial^\alpha u(x) + a_0[x, u(x), Du(x), \ldots, D^{k-1}u] = 0.
	\]
	A PDE is \emph{fully nonlinear}\index{fully nonlinear} if it is none of the types above.
\end{definition}

\begin{exbox}
	\begin{itemize}
		\item Linear PDE: Take the Laplace,
			\[
			\Delta u = \sum_{i = 1}^n \frac{\partial^2 u}{\partial x_i^2} = 0.
			\]
		\item Semilinear PDE:
			\[
			\Delta u = \left( \frac{\partial u}{\partial x_1} \right)^2.
			\]
		\item Quasilinear PDE:
			\[
				u \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = \frac{\partial u}{\partial x} \text{ on } \mathbb{R}^2.
			\]
		\item Fully nonlinear:
			\[
			\frac{\partial^2 u}{\partial x^2} \frac{\partial^2 u}{\partial y^2} - \left( \frac{\partial^2 u}{\partial x\partial y} \right)^2 = 0.
			\]
	\end{itemize}
	We also have some examples from physics:
	\begin{itemize}
		\item Newtons' equations.
		\item Euler incompressibility equation.
		\item Navier-Stokes equation.
		\item Boltzmann equation.
		\item Vlasov equation.
		\item Schr\"odinger equation.
		\item Einstein equations.
		\item Dirac equation.
	\end{itemize}
	Moreover here are equations from math:
	\begin{itemize}
		\item Cauchy-Riemann equations.
		\item Ricci flow. $\partial_t g_{ij} = -2 R_{ij}$.
	\end{itemize}
\end{exbox}

\newpage

\section{The Cauchy-Kovalevskaya Theory}%
\label{sec:ck}

This is the only ``general'' theorem that can be salvaged from ODEs. Some concepts that arise are:
\begin{itemize}
	\item Non-characteristic Cauchy data.
	\item Principal symbols.
	\item Basic classification of PDEs.
\end{itemize}
However the analyticity used in this theory is most often not satisfying, in the functional setting.

\subsection{Real Analyticity}%
\label{sub:ra}

\begin{definition}
	Given $U \subseteq \mathbb{R}^n$ open, a function $f : U \to \mathbb{R}$ is \emph{real analytic}\index{real analytic} near $\tilde x \in U$ if there is $r > 0$ and real constants $(f_\alpha)$ so that the series
	\[
	\sum_{\alpha \geq 0} f_\alpha(x - \tilde x)^\alpha
	\]
	converges for $x \in B(\tilde x, r)$ to $f(x)$.

	If $f : U \to \mathbb{R}^n$, for $n \geq 2$, then it is real analytic if $f_i$ is real analytic for $i = 1, \ldots, n$.

	$f$ is \emph{real analytic} in $U$ if it is real analytic near each point of $U$. This is sometimes denoted as
	\[
	f \in C^\omega (U).
	\]
\end{definition}

\begin{exbox}
	Simple examples of real analytic functions include polynomials, exponential functions, trigonometric functions.

	The map $z \mapsto \overline{z}$, i.e. conjugation, is not $\mathbb{C}$-differentiable, but it is real analytic in $\mathbb{R}^2$.

	The function
	\[
	f(x) =
	\begin{cases}
		e^{-1/x^2} & x \neq 0, \\
		0 & x = 0
	\end{cases}
	\]
	is $C^\infty$, but not real analytic. In fact any $C_c^\infty$ function cannot be real analytic.

	Liouville's theorem does not hold, by either $\sin$ or $1/(1 + x^2)$.
\end{exbox}

Real analyticity is local, meaning if $f$ is real analytic near $\tilde x$, then $f$ is real analytic in $B(\tilde x, r) \subseteq U$ for some $r > 0$.

\begin{proposition}
	Given $U \subseteq \mathbb{R}^n$ open and non-empty, then $f : U \to \mathbb{R}$ is real analytic on $U$ if and only if $f \in C^\infty$, and for any $K \subseteq U$ compact, there are $C(K)$, $r(K) > 0$ so that the following growth conditions holds: for all $x \in K$, $\alpha \in \mathbb{N}^n$,
	\[
	|\partial^\alpha f(x)| \leq C(K) \frac{\alpha!}{r(K)^{|\alpha|}}.
	\]
\end{proposition}

\begin{remark}
	\begin{itemize}
		\item[]
	\item When $U \subseteq \mathbb{R}$, another equivalent definition is, $f$ is real analytic on $U$ if it can be locally extended to a $\mathbb{C}$-differentiable function near each point of $U$.
	\item When $U = \mathbb{R}^n$, real analyticity is also equivalent to exponential decay in the Fourier variables.
	\end{itemize}
\end{remark}

% lecture 4

\begin{proofbox}
	Recall that, if
	\[
	\sum_{\alpha \geq 0} f_\alpha (x - \tilde x)^\alpha
	\]
	converges at $x$ such that $|x - \tilde x| = r$, then the general term is bounded by
	\[
	|f\alpha| \leq Cr^{-|\alpha|}.
	\]
	Hence for $|x - \tilde x| < r$, we have absolute convergence.

	Recall for a function, the \emph{radius of convergence}\index{radius of convergence} is the largest $r \geq 0$ so that we have a point of convergence at a distance $r$.

	The easy implication is the forwards. Suppose that in $B(\tilde x, r) \subseteq U$, we have the power series
	\[
	f(x) = \sum f_\alpha (x - \tilde x)^\alpha,
	\]
	with radius of convergence at least $r$. Then from a standard theorem, $f$ is smooth in $B(\tilde x, r)$ with
	\[
	\partial^\alpha f(\tilde x) = (f_\alpha) \alpha!.
	\]
	We know that $|f_\alpha| \leq C \bar r^{-|\alpha|}$, for some $\tilde r < \bar r < r$. Then for all $x \in \bar B(\tilde x, \tilde r)$, and $\beta \in \mathbb{N}^n$,
	\begin{align*}
	|\partial^\beta f(x)| &= \left|\partial^\beta  \left( \sum_{\alpha \geq 0} f_\alpha (x - \tilde x)^\alpha \right) \right| \\
			      &\leq \sum_{\alpha \geq \beta} |f_\alpha| \frac{\alpha!}{(\alpha - \beta)!} |x - \tilde x|^{|\alpha - \beta|} \\
			      &\leq C \sum_{\alpha \geq \beta} \bar r^{-|\alpha|} \frac{\alpha!}{(\alpha - \beta)!} \tilde r^{|\alpha - \beta|} \\
			      &\leq C \bar r^{|\beta|} \sum_{\alpha \geq \beta} \left( \frac{\tilde r}{\bar r} \right)^{|\alpha - \beta|} \frac{\alpha!}{(\alpha - \beta)!}.
	\end{align*}
	Let $\lambda = \tilde r/ \bar r < 1$. Then by observation,
	\[
		(1 - \lambda)^{-1} = \sum_{j \geq 0} \lambda^{j}.
	\]
	Taking the $m$'th partial derivative,
	\[
	\frac{m!}{(1 - \lambda)^{m+1}} = \sum_{j \geq m} \frac{j!}{(j - m)!} \lambda^{j - m}.
	\]
	If we apply this, then
	\begin{align*}
		|\partial^\beta f(x)| & \leq C r^{|\beta|} \sum_{\alpha \geq \beta} \frac{\alpha!}{(\alpha - \beta)!} \lambda^{|\alpha - \beta|} \\
				      &\leq C |r|^{|\beta|} \frac{\beta!}{(1 - \lambda)^{|\beta| + n}} \\
				      &\leq \frac{C \beta!}{(1 - \lambda)^n} \left( \frac{r}{1 - \lambda} \right)^{|\beta|}.
	\end{align*}
	For the other direction, consider our assumption on $K = \bar B(\tilde x, r) \subseteq U$, there exists $\tilde C, \tilde r > 0$ such that for all $x \in K$, $\alpha \in \mathbb{N}^n$,
	\[
	|\partial^\alpha f(x)| \leq \tilde C \tilde r^{-|\alpha|} \alpha!.
	\]
	Choose $x \in B(\tilde x, \tilde r/2)$, and Taylor expand, so
	\[
	f(x) = \sum_{|\alpha| \leq k} \partial^\alpha f(x) \frac{(x - \tilde x)^\alpha}{\alpha!} + \sum_{|\alpha| = k + 1} R_\alpha(x) (x - \tilde x)^\alpha.
	\]
	If $n = 1$, we have
	\[
	R_\alpha(x) = \frac{|\alpha|}{\alpha!} \int_0^1 (1 - t)^{|\alpha| - 1} \partial^\alpha f( \tilde x + t (x - \tilde x)) \diff t.
	\]
	From the growth condition, the main part of the expansion is a partial sum of an absolute series, and
	\begin{align*}
		\left| \sum_{|\alpha| = k + 1} R_\alpha(x) (x - \tilde x)^\alpha \right| &\leq \sum_{|\alpha| = k+1} |R_\alpha(x)| \left( \frac{\tilde r}{2} \right)^{k + 1}, \\
											|R_\alpha(x)| &\leq \tilde C \frac{|\alpha|}{\alpha!} \int_0^1 (1-t)^{|\alpha|-1} \tilde r^{-(k+1)} \diff t \\
												      &\leq \tilde C \frac{\tilde r^{-(k+1)}}{\alpha!}.
	\end{align*}
	So,
	\begin{align*}
		I &= \left| \sum_{|\alpha| = k + 1} R_\alpha(x) (x - \tilde x)^\alpha \right| \leq \tilde C \tilde r^{-(k+1)} \left( \frac{\tilde r}{2} \right)^{k+1} \cdot \binom{k+n}{n-1} \\
		  &\leq C' (k + n)^{n-1} 2^{-(k+1)} \to 0
	\end{align*}
	as $k \to \infty$, which shows the convergence of the Taylor series.
\end{proofbox}

\begin{definition}
	Let
	\[
	f = \sum_{\alpha \geq 0} f_\alpha x^\alpha, \qquad g = \sum_{\alpha \geq 0} g_\alpha x^\alpha
	\]
	be two formal power series. Then $g$ \emph{majorizes}\index{majorization} $f$, or $g$ is a \emph{majorant} of $f$, written $g \gg f$ if $g_\alpha \geq |f_\alpha|$ for all $\alpha \in \mathbb{N}^\alpha$.

	If $f, g$ are $\mathbb{R}^m$-valued, then each component $g_j \gg f_j$, for $j = 1, \ldots, m$.
\end{definition}

\begin{proposition}
	Given $f, g$ formal power series:
	\begin{enumerate}[\normalfont(i)]
		\item If $g \gg f$ and $g$ converges for $\|x\| < r$, then $f$ converges for $\|x\| < r$ as well.
		\item If $f$ converges for $\|x\| < r$, and $\tilde r \in (0, r/\sqrt n)$, there is a majorant $g \gg f$ which converges in $\|x\| < \tilde r$.
	\end{enumerate}
\end{proposition}

\begin{proofbox}
	

	(i) Let $x \in B(0, r)$, then
	\begin{align*}
		\sum_{\alpha \leq k} |f_\alpha x^\alpha| &\leq \sum_{|\alpha| \leq k} |f_\alpha| |x_1|^{\alpha_1} \cdots |x_n|^{\alpha_n} \\
							 &\leq \sum_{|\alpha| \leq k} g_\alpha |x_1|^{\alpha_1} \cdots |x_n|^{\alpha_n}.
	\end{align*}
	If $y = (|x_1|, \ldots, |x_n|)$, then $\|y\| = \|x\| < r$, and since $g$ converges for $\|x\| < r$ it converges for $y$.

	(ii) Take $\tilde r \in (0, r/\sqrt n)$ and $y = (\tilde r, \ldots, \tilde r)$. Then $\|y\| = \sqrt n \tilde r < r$ 

	Now $f$ converges on $y$, so the general term is bounded:
	\[
	|f_\alpha| \leq C \tilde r^{-|\alpha|}.
	\]
	Now consider
	\[
	\bar f(x) = \frac{C}{1 - (x_1 + \cdots + x_n)/\tilde r},
	\]
	for $x \in B(0, \tilde r/\sqrt n)$. Then
	\begin{align*}
		\bar f(x) &= C \sum_{k \geq 0} \tilde r^{-k} \left( \sum_{|\alpha| = k} \frac{|\alpha|!}{\alpha!} x^\alpha \right) \\
			  &= C \sum_{\alpha \geq 0} \frac{\tilde r^{-|\alpha|} |\alpha|!}{\alpha!} x^\alpha.
	\end{align*}
	We can check that $\alpha! \leq |\alpha|!$, so $f \ll \bar f$.

	Another majorant we can consider is
	\begin{align*}
		\bar f(x) &= C \prod_{i = 1}^n \left( \frac{1}{1 - (x_i/\tilde r)} \right) = C \prod_{\alpha \geq 0} \left( \frac{x}{\tilde r} \right)^{\alpha} \\
			  &= C \sum_{\alpha \geq 0} \tilde r^{-|\alpha|} x^\alpha.
	\end{align*}
\end{proofbox}

\subsection{Cauchy-Kovalevskaya for ODEs}%
\label{sub:ck_ode}

\begin{theorem}
	Let $a, b > 0$, and $u_0 \in \mathbb{R}$. Consider $F : (u_0 - b, u_0 + b) \to \mathbb{R}$ real analytic, and $u : (-a, a) \to (u_0 - b, u_0 + b)$ a $C^1$ solution to
	\[
	u'(t) = F(u(t)).
	\]
	Then $u$ is real analytic on $(-a, a)$.
\end{theorem}

% lecture 5

\begin{proofbox}
	We prove this in many ways. The first is by Picard iteration.

	Define
	\begin{align*}
		u_{l+1}(z) &= u_0 + \int_0^z F(u_l(z)) \diff z, \\
		u_0(z) &= u_0,
	\end{align*}
	where we exited $F$ to be homomorphic near the origin. We may prove that $(u_l)$ is Cauchy in the $\|\cdot\|_\infty$ norm, on a small enough neighbourhood of $t = 0$. Here we use the bound on $F'$.

	Now $u_l \to u$ converges uniform locally. By induction, we can show $u_l$ is $\mathbb{C}$-differentiable, so by Morera's theorem, $u$ is $\mathbb{C}$-differentiable.

	The second proof is by separation of variables. If $F(0) = 0$, then $u = 0$, and there is nothing to prove.

	Otherwise, $F \neq 0$ near $0$, and we may write
	\[
	G(y) = \int_0^y \frac{\diff x}{F(x)},
	\]
	for $y \in (-b', b')$ for some $0 < b' < b$ small enough. Then we find that
	\[
	\frac{\diff}{\diff t} G(u(t)) = \frac{F(u(t))}{F(u(t))} = 1.
	\]
	For $t \in (-a', a')$, $G(u(0)) = G(0) = 0$, and $G(u(t)) = t$, and
	\[
	G'(0) = \frac{1}{F(0)} \neq 0.
	\]
	So there exists a smaller $(-a'', a'') \subseteq (-a', a')$ such that $G^{-1}$ is defined, and $F$ is real analytic. Then since $G$ is real analytic, $G^{-1}$ is as well, so
	\[
	u(t) = G^{-1}(t)
	\]
	is real analytic on $(-a'', a'')$.

	The third proof is by embedding the equation in a larger continuum of equations. For $z \in \mathbb{C}$, consider
	\begin{align*}
		u'_z(t) &= z F(u_z(t)), \\
		u_1(0) &= 0,
	\end{align*}
	where the original equation is $z = 1$.

	For $|z| < 2$, and $|t| < \eps$ small enough, Picard-Lindel\"of gives a solution uniformly in $|z| < 2$ by having Lipschitz constant on $zF$ uniformly in $|z| < 1$.

	Defining
	\[
	\partial z = \left( \frac{\partial x - i \partial y}{2} \right), \qquad \partial \bar z = \left( \frac{\partial x + i \partial y}{2}\right),
	\]
	then a function $f$ is complex differentiable if and only if
	\[
	\partial \bar z(f) = 0,
	\]
	Taking our function to be $u_z'$, we find
	 \[
		 \partial t \partial \bar z [u_z(t)] = z F'(u_z(t)) \partial \bar z[u_z(t)].
	\]
	We can integrate this to find
	\[
		\partial \bar z[u_z(t)] = \exp \left[ \int_0^t z F'(u_z(s)) \diff s \right] \partial \bar z[u_z(0)],
	\]
	where the last term is 0, hence the entire thing is 0. So, for $|t|$ small enough and $|z| < 2$, $z \mapsto u_z(t)$ is $\mathbb{C}$-differentiable. Hence, we can write
	\[
	u_1(t) = \sum_{n = 0}^\infty \frac{1^n}{n!} \frac{\partial^n}{\partial z^n} [u_z(t)] \biggr|_{z = 0}.
	\]
	For $|z| < 2$ real,
	\[
		\frac{\partial^n}{\partial z^n} [u(zt)] = t^n u^{(n)}(0),
	\]
	where the latter is real differentiable. This implies convergence and equality,
	\[
	u(t) = u_1(t) = \sum_{n = 0}^{\infty} \frac{t^n}{n!} u^{(n)}(0).
	\]

	Another proof is by majorant. If $u, F$ are smooth with
	\[
	u'(t) = F(u(t)),
	\]
	then we will induct on $u \in C^k((-a, a))$, $k \geq 1$. Then note $F \circ u \in C^k(\cdot)$, so $u' \in C^k$, hence $u \in C^{k+1}$. For example,
	\begin{align*}
		u^{(1)}(t) &= F^{(0)}(u(t)), \\
		u^{(2)}(t) &= F^{(1)}(u(t)) \times u^{(1)}(t) = F^{(1)}(u(t)) \times F^{(0)}(u(t)), \\
		u^{(3)}(t) &= F^{(2)}(u(t)) \times F^{(0)}(u(t))^2 + F^{(1)}(u(t))^2 F^{(0)}(u(t)),
	\end{align*}
	and we can go on. By induction, we can show $u^{(k)}(t)$ is a polynomial in $F^{(0)}(u(t)), F^{(1)}(u(t)), \ldots, F^{(k-1)}(u(t))$, with non-negative integer coefficients, so write
	\[
	u^{(k)}(t) = p_k(F^{(0)}(u(t)), F^{(1)}(u(t)), \ldots, F^{(k)}(u(t))).
	\]
	For example,
	\begin{align*}
		p_1(x_1) &= x_1, \\
		p_2(x_1, x_2) &= x_1 x_2, \\
		p_3(x_1, x_2, x_3) &= x_1^2 x_3 + x_1x_2^2.
	\end{align*}
	These polynomials are universal; they do not depend on $F$. If $G \gg F$, then $|G^{(k)}(0)| > |F^{(k)}(0)|$ for all $k$, and so
	\begin{align*}
		p_k(F^{(0)}(0), \ldots, F^{(k-1)}(0)) &\leq p_k(|F^{(0)}(0)|, \ldots, |F^{(k-1)}(0)|) \\
						      &\leq p_k(G^{(0)}(0), \ldots, G^{(k-1)}(0)).
	\end{align*}
	Assume that we have $G \gg F$, and that $v$ is a solution to
	\begin{align*}
		v'(t) &= G(v(t)), \\
		v(0) &= 0,
	\end{align*}
	and $v$ is real analytic near $0$. Then,
	\[
	v^{(k)}(0) = p_k(G^{(0)}(0), \ldots, G^{(k-1)}(0)),
	\]
	so that $v^{(k)}(0) > |u^{(0)}(0)|$, for all $k \geq 0$. Since $v$ is real analytic,
	\[
	v(t) = \sum_{k \geq 0} v^{(k)}(0) \frac{t^k}{k!},
	\]
	which is absolutely convergent near $0$. Define
	\[
	\tilde u(t) = \sum_{k \geq 0} p_k(F^{(0)}(0), \ldots, F^{(k-1)}(0)) \frac{t^k}{k!},
	\]
	ons the same disc of convergence. This $\tilde u$ is real analytic near $0$, and since $\tilde u(t)$ and $F(\tilde u(t))$ are real analytic and all derivatives agree at $t = 0$, they are equal near $t = 0$.

	Now all we need to do is construct $G$ and $v$. This is possible since
	\[
	|F^{(k)}(0)| \leq C k! r^{-k},
	\]
	for $k \geq 0$ and some $C, r > 0$. So we can define
	\[
	G(x) = \frac{Cr}{r - x},
	\]
	for $|x| < r$. Then the solution to
	\begin{align*}
		v'(t) &= G(v(t)), \\
		v(0) &= 0
	\end{align*}
	is
	\[
		v(t) = r - r \sqrt{1 - \frac{2 C t}{r}}.
	\]
	This is real analytic for $|t| < r/2C$.
\end{proofbox}

% lecture 6

\begin{theorem}
	Let $a, b > 0$, $u_0 \in \mathbb{R}^m$ for $m \geq 1$, and $F : B(u_0, b) \to \mathbb{R}^m$ real analytic.

	Let $u : (-a, a) \to B(u_0, b)$ be a $C^1$ solution to $u'(t) = F(u(t))$, with $u(0) = u_0$.

	Then $u$ is real analytic in $(-a, a)$.
\end{theorem}

\begin{proofbox}
	We can extend proofs 1 and 3 from the scalar case.

	To extend the method of majorants, for $C, r > 0$ well chosen, set
	\[
	G(x_1, \ldots, x_m) = (G_1(x_1, \ldots, x_m), \ldots, G_m(x_1, \ldots, x_m)),
	\]
	\[
	G_1 = \cdots = G_m = \frac{Cr}{r - x_1 - \cdots - x_m}.
	\]
	We can reduce the proof to proving that the solution $v$ to the auxiliary problem
	\begin{align*}
		v'(t) &= G(v(t)),\\
		v(0) &= 0.
	\end{align*}
	By symmetry, we solve in the form
	\[
	v_1(t) = \cdots = v_m(t) = w'(t),
	\]
	\[
	w'(t) = \frac{Cr}{r - m w(t)}.
	\]
	This solves as
	\[
		w(t) = \frac{r}{m} - \frac{r}{m} \sqrt{1 - \frac{2 C m t}{r}}.
	\]
\end{proofbox}

\subsection{Cauchy-Kovalevskaya for PDEs}%
\label{sub:ck_pde}

The CK theorem only extends for $k$-th order quasilinear PDEs, so for $x \in U \subseteq \mathbb{R}^m$,
\[
\sum_{|\alpha| = k} a_\alpha (D^{k-1} u, \ldots, Du, u, x) \partial^\alpha_x u + a_0 (D^{k-1} u, \ldots, Du, u, x) = 0.
\]
\begin{remark}
	For $k = 1$, we have an alternative proof by the method of characteristics.
\end{remark}

\subsection{Cauchy Problem and Statement}%
\label{sub:cp_s}

\begin{definition}
	Give $U \subseteq \mathbb{R}^n$ open and non-empty, we say that $\Sigma \subseteq U$ is a \emph{smooth}\index{smooth} (resp. real analytic) hypersurface near $x \in \Sigma \subseteq U$ if there exists $\eps > 0$ and $\Phi : B(x, \eps) \to V \in \mathbb{R}^n$ so that
	\[
		\phi\left( \Sigma \cap B(x, \eps) \right) = \{y_n = 0\} \cap V,
	\]
	and $\phi(x) = 0$, with:
	\begin{itemize}
		\item $\phi$ bijective,
		\item $\phi, \phi^{-1}$ smooth (resp. real analytic).
	\end{itemize}
	$\Sigma \subseteq U$ is a smooth (resp. real analytic) hypersurface if it satisfies the previous definition around any $x \in \Sigma$.
\end{definition}

\begin{remark}
	$\Sigma$ a submanifold is smooth (resp. real analytic) which is embedded with normal unit vector???
\end{remark}

The definition implies there admits a normal unit vector $N : \Sigma \to \mathbb{R}^n$, which is perpendicular to the tangent space, and smooth (resp. real analytic).

Given a parametrization $\Psi : B_{\mathbb{R}^{n-1}}(0, \eps) \times (-\eps, \eps) \to U_x$, define
\[
\Psi(y) = \tilde \Psi(\tilde y) + y_n N(\psi(\tilde y)),
\]
where $\tilde y = (y_1, \ldots, y_{n-1})$, and $\tilde \Psi : B_{\mathbb{R}^{n-1}}(0, \eps) \to \Sigma \cap U_x$. Then for this parametrization,
\[
\partial y_n \Psi(y) = N(\tilde \Psi(\tilde \psi)).
\]
The tangent space to $\Sigma$ is given, for $x' \in U_x$, by
\[
x' + \spn \{ \partial y_1 \tilde \Psi(y'), \ldots, \partial_{n-1} \tilde \Psi(y')),
\]
where $\Psi(y, 0) = \tilde \Psi(y', 0) = x'$. So,
\begin{itemize}
	\item $\phi = \Psi^{-1}$ defines a chart.
	\item Take $\varphi = \phi_n$, the last component. Then note $\Sigma \cap U_x = \{\varphi = 0\} \cap U_x$. Moreover,
		\[
		\nabla_x \varphi = N
		\]
		on $U_x \cap \Sigma$.
\end{itemize}

Indeed, $\varphi$ satisfies $\varphi(\psi(y)) = y_n$. Differentiating this condition,
\[
\nabla \varphi \cdot \partial y_i \psi = 0,
\]
so $\nabla \varphi$ is collinear to $N$. Differentiating along $y_n$,
\[
\nabla_x \varphi \cdot N = 1,
\]
so $\phi_x \varphi = N$ on $\Sigma$.

\begin{definition}
	Given $\Sigma \subseteq U \subseteq \mathbb{R}^n$ a smooth or real analytic hypersurface, and $j \geq 1$, we define the $j$'th \emph{normal derivative}\index{normal derivative} of the function $u$ to $\Sigma$ as
	\[
	\partial^j_N u = \sum_{|\alpha| = j} (\partial^\alpha_x u(x)) N(x)^\alpha = \sum_{\alpha_1 + \cdots + \alpha_n = j} \left( \frac{\partial^j u(x)}{\partial x_1^{\alpha_1} \cdots \partial x_n^{\alpha_n}}\right) N_1(x)^{\alpha_1} \cdots N_n(x) \alpha^{n}.
	\]
\end{definition}

\begin{remark}
	For $j = 1$,
	\[
	\partial^1_N u = (\nabla u \cdot N).
	\]
\end{remark}

\begin{definition}
	Given $\Sigma \subseteq  \mathbb{R}^n$ as before, and $g_0, g_1, \ldots, g_{k-1} : \Sigma \to \mathbb{R}$ smooth (resp. real analytic), the \emph{Cauchy problem}\index{Cauchy problem} is finding solutions to
	\[
	\sum_{|\alpha| = k} a_\alpha (D^{k-1} u, \ldots, Du, u, x) \partial^\alpha_x u + a_0(D^{k-1}u, \ldots, Du, u, x) = 0,
	\]
	with $u(x) = g_0(x), \partial^1_N u = g_1(x), \ldots, \partial^{k-1}_N u = g_{k-1}$ on $\Sigma$.
\end{definition}

The natural question to ask is, if we are given the above Cauchy data on $\Sigma$, does this determine all derivatives locally on $\Sigma$?

Let us start with the flat case: $U = \mathbb{R}^n$, and $\Sigma = \{x_n = 0\}$. Then $N(x) = e_n$ is constant, and
\[
\partial^j_N u(x) = \partial^j_{x_n} u(x),
\]
on $x = (x', 0) \in \Sigma$. The second condition gives
\[
\partial^{\alpha}_x u(x) = \partial^{\alpha'}_{x'} \partial^j_{x_n} u(x) = \partial^{\alpha'}_{x'} g_j(x),
\]
for $\alpha' \in \mathbb{N}^{n-1}$ and $j = 0, \ldots, k-1$. The first missing partial derivatives is $\partial^{k}_{x_n} u$ on $\Sigma$. But we can find this using the PDE: if
\[
A(x) = a_{(0, \ldots, 0, k)}(D^{k-1}u, \ldots, Du, u, x) \neq 0,
\]
then the first condition gives
\[
\partial^k_{x_n} u(x) = - \sum_{|\alpha| = k} \frac{a_\alpha(\cdots)}{A(x)} \partial^\alpha_x u - \frac{a_0(\cdots)}{A(x)}
\]
on $\Sigma$. We can continue; differentiating again,
% lecture 7

\[
0 = \sum_{|\alpha| = k} a_\alpha(D^{k-1} u, \ldots, Du, u, x) \partial^\alpha_x \partial_{x_n} u(x) + \tilde a_0 (D^k u, D^{k-1} u, \ldots),
\]
where
\[
\tilde a_0 (\cdots) = \sum_{|\alpha| = k} \partial_{x_n} (a_\alpha(\cdots)) \partial^\alpha_x u + \partial_{x_u}(a_0(\cdots)).
\]
If $A(x) \neq 0$, then
\[
g_{k+1}(x) = \partial^{k+1}_{x_n} u = \sum_{|\alpha| = k} \frac{a_\alpha(\cdots)}{A(x)} \partial^\alpha_x \partial_{x_n} u - \frac{\tilde a_0(\cdots)}{A(x)}.
\]
This is a function of $g_0, \ldots, g_k$, so in turn a function of only $g_0, \ldots, g_{k-1}$. So for the flat case, we ar happy if $A(x)$ is non-zero. In general, we want
\[
A(x) = \sum_{|\alpha| = k} a_\alpha (D^{k-1} u, \ldots, Du, u, x) N(x)^\alpha \neq 0
\]
on $\Sigma$.

If $u$ is a solution in the general case, then $v = v(y) = u(\psi(y))$ is a solution to
\[
0 = \sum_{|\alpha| = k} b_\alpha (D^{k-1} v(y), \ldots, D v(y), v(y), y) + b_0 (D^{k-1} v(y), \ldots, D v(y), v(y), y).
\]
This is a PDE of the same type, and the coefficients $b_\alpha$ depends on the coefficients $a_\alpha$. The boundary conditions on $v$ are
\begin{align*}
	\partial^j_{y_n} v(y) &= \partial^j_{y_n} [u(\psi(y))] = \sum_{|\alpha| = j} \partial^\alpha_{x} u(\psi(y))(\partial_{y_n} \psi)^\alpha \\
			      &= \partial^j_N u,
\end{align*}
so we get that
\[
\partial^j_{y_n} v(\tilde y, 0) = g_j(something)
\]
The non-characteristic condition in the original variables means
\[
\nabla \phi_n = N,
\]
on $\Sigma$. This is
\[
\sum_{|\alpha| = k} a_\alpha(\cdots) \partial^\alpha_{x} u.
\]
Collecting all $\partial^k_{y_n} v$ terms, we find
\[
	\partial^\alpha_x u = \partial^\alpha_x(v \circ \phi) = (\partial^k_{y_n} v) (\nabla_x \phi) + \text{higher order terms}.
\]
He yaps on idk what he is saying.

\begin{theorem}
	Let $\Sigma \subseteq U \subseteq \mathbb{R}^n$ be a real analytic hyerpsurface, with a PDE and Cauchy data as before, where $a_\alpha, a_0$ and $g_j$ are real analytic.

	Then for any $x \in \Sigma \subseteq U$, there is a neighbourhood around $x$ in which there exists a unique real analytic solution to the PDE with prescribed Cauchy data.
\end{theorem}

To prove this, the idea is to use the method of majorants, with universal polynomials and a non-charactericity condition.

First we have a reduction step: without loss of generality, our base point is $x = 0$, and with $\phi$ and $\psi$ we reduce to $\Sigma = \{x_n = 0\}$. Then the boundary conditions are
\[
\partial^j_{x_n} u = g_j
\]
on $\Sigma$. By our condition,
\[
A(x) = a_{(0, \ldots, 0, k)} (\cdots) \neq 0,
\]
so we can divide by it, and reduce to $A = 1$. Moreover we can reduce to $g_0 = g_1 = \cdots = g_{k-1} = 0$ by subtracting to $u$ an appropriate real analytic function, for example
\[
G(y) = \sum_{j = 0}^{k-1} g_j(\tilde x) \frac{x_n^j}{j!},
\]
with
\[
\partial^j_{x_k}(u - G) = 0
\]
on $\{x_n = 0\}$.

Finally, we reduce to a first-order equation for a system of equations, by changing our unknown $u$ into
\[
	(u, Du, D^2 u, \ldots, D^{k-1} u).
\]
This produces a much nicer PDE of the form
\[
	\partial_{x_n} u = \sum_{j = 1}^{k-1} b_j (u(x), \tilde x) \partial_{x_j} u + b_0 (u(x), \tilde x),
\]
where we avoid $x_n$ dependency by adding if necessary one more component $x_n$ to $u$. Our boundary conditions are $u = 0$ on $\Sigma = \{x_n = 0\}$, and also $b_j : \mathbb{R}^m \times \mathbb{R}^{n-1} \to \mathbb{R}^{m \times m}$ to something, $b_0 : \mathbb{R}^{m} \times \mathbb{R}^{n-1} \to \mathbb{R}^m$ are real analytic near zero.

The second step is to prove there are universal polynomials with non-negative integer coefficients $p_{\alpha, i}$ such that
\[
\partial^\alpha_x u_i(0) = p_{\alpha, i} ((D^\beta b_{j})_{\ell_1, \ell_2}, (D^\beta b_0)_\ell)(0, 0),
\]
for $|\beta| \leq |\alpha| - 1$, $\ell$ appropriate. We prove this by induction on $\alpha_n$.

% lecture 8

\begin{proofbox}
	This is done by induction on $a_n$: Differentiate $u(\tilde x, 0)= 0$ near $\tilde x = 0$ to get
	\[
	\partial^{\alpha}_x u(0) = 0,
	\]
	which gives $\alpha_n = 0$. For $\alpha_n = 1$, we look at
	\[
	\partial^{\tilde \alpha}_{\tilde x} \partial^1_{x_n} u.
	\]
	We are actually now just going to look at the general case, when we differentiate the PDE with
	\[
	\partial^{\tilde \alpha}_{\tilde x} \partial^{\alpha_n - 1}_{x_n},
	\]
	which gives
	\[
		\partial^{\tilde \alpha}_{\tilde x} \partial^{\alpha_n}_{x_n} u(0) = \partial^{\tilde \alpha}_{\tilde x} \partial^{\alpha_n - 1}_{x_n}\left[ \sum b_j (\cdot) \partial x_j u + b_0\right].
	\]
	For $\alpha_n = 1$, we have no $\partial_{x_n}$ on the RHS, so we get only $D^{\tilde \alpha}_{2}b_0(0, 0)$. To prove the induction step, note
	\[
		\partial^{\tilde \alpha}_{\tilde x} \partial^{\ell + 1}_{x_n} u(0) = \partial^{\tilde \alpha}_{\tilde x} \partial^{\ell}_{x_n} \left[ \sum_{j = 1}^{n-1} b_j(u(x), \tilde x) \partial x_j u + b_0(\cdots) \right],
	\]
	which is a polynomial with coefficients in $\mathbb{N}$, after applying the induction hypothesis for $\ell$.
\end{proofbox}

Our candidate solution is
\[
u(x) = \sum_{\alpha \geq 0} \partial^{\alpha}_x u(0) \frac{x^\alpha}{\alpha!},
\]
where $\partial^{\alpha}_x u$ is defined by $p_{\alpha, i} (D b_j(0), D b_0(0))$. If we are able to find a majorant $b_j^\ast \gg b_j$, and $b_0^\ast \gg b_0$, then
\begin{align*}
	|\partial^{\alpha}_x u_i(0)| &\leq |p_{\alpha, i} (D b_j(0), D b_0(0))| \\
				     &\leq p_{\alpha, i} (|Db_j(0)|, |Db_0(0)|) \\
				     &\leq p_{\alpha, i} (Db_j^{\ast}(0), D b_0^{\ast}(0)) \\
				     & = \partial^{\alpha}_x v_i(0),
\end{align*}
where $v$ is a solution to
\[
\partial x_n v = \sum b_j^{\ast} (v(x), \tilde x) \partial_{x_j} v + b_)(v(x), \tilde x),
\]
and $v = 0$ on $\Sigma$. Now $v \gg u$, and if $v$ is real analytic near $0$, then so is $u$. Then
\[
\partial x_n u - \sum b_j(u(x), \tilde x) \partial_{x_j} u - b_0(u(x), \tilde x) = S(x)
\]
is an entire series with non-zero radius of convergence around 0, with $\partial^{\alpha}_x S(0) = 0$ for all $\alpha \in \mathbb{N}$. Hence $S = 0$ near $0$, and $u$ is a solution which is unique by real analyticity.

Now all that is left is to define the majorants. Define
\begin{align*}
	b_j^{\ast} &= g J_{m\times m}, \\
	b_0^{\ast} &= g U_{m},
\end{align*}
where $J$ is the all $1$'s matrix, and $U$ is the all $1$'s vector. Then we can define
\[
g(y_1, \ldots, y_m, x_1, \ldots, x_{n-1}) = \frac{Cr}{r - (x_1 +\cdots + x_{n-1}) - (y_1 + \cdots + y_m)}.
\]
Then we find that
\[
\partial^{\alpha} g(0) = C \alpha! r^{-|\alpha|},
\]
which dominates the entries of $b_j$ and $b_0$ for suitable $C, r > 0$. The solution to the auxiliary equation then becomes, for $n = 2$,
\[
	v(x) = \frac{n m C t}{r - (x_1 + \cdots + x_{n-1}) + \sqrt{(r - x_1 - \cdots - x_{n-1})^2 - 2nmCrx_n}} U_m,
\]
and for $n \geq 3$ we find
\[
	v(x) = \frac{1}{nm} \left[ (r - x_1 - \cdots - x_{n-1}) - \sqrt{(r - x_1 - \cdots - x_{n-1})^2 - 2nmCr x_n} \right] U_m.
\]
These are real analytic near $0$, so we are done.

The question then becomes, how did we get these formulas? By symmetry, the first $n-1$ variables must play the same role, and the components of $v$ must be the same, so
\[
v_1 = \cdots = v_m = w,
\]
and
\[
w = w(x_1 + \cdots + x_{n-1}, x_n) = w(\xi, x_n).
\]
This gives a scalar equation
\begin{align*}
	\partial_t \omega &= \frac{Cr}{r - \xi - m w} [(n - 1)m \partial_\xi w + 1], \\
	w(\xi, 0) &= 0.
\end{align*}

As an exercise, we can find $\xi(t), \eta(t)$ solving
\begin{align*}
	\xi'(t) &= \frac{-(n-1)m Cr}{r - \xi(t) - m \eta(t)}, \\
	\eta'(t) &= - \frac{Cr}{r - \xi(t) - m \eta(t)},
\end{align*}
where we initialize $\xi(0) = \xi_0$, $\eta(0) = 0$. Then $w(\xi(t), t) = \eta(t)$ defines $w$ that solves the PDE
\[
\xi'(t) (\partial_\xi w)(\xi(t), t) + (\partial_t w)(\xi(t), t) = \eta'(t),
\]
at $(\xi(t), t)$. We can then solve for $\xi(t)$ and $\eta(t)$, and invert $\xi_0 \mapsto \xi(t)$ for $t$ small enough.

%\newpage
%
%\section{Limitations of CK and Classification}%
%\label{sec:lim_ck}

\subsection{Limitations}%
\label{sub:lims}

There are many limits of CK.
\begin{enumerate}[(i)]
	\item Consider the heat equation:
		\begin{align*}
			\partial_t u &= \partial^2_x u, \\
			u(0, x) &= \frac{1}{1 + x^2},
		\end{align*}
		where the surface is $\Sigma = \{t = 0\}$. The non-characteristic condition means that $a_{(2, 0)} \neq 0$, but this is not true in the above. This is due to the fact we cannot solve the PDE for negative times.
	\item If we have a diffusion equation of the form
		\[
		\partial_t^{k} u = \sum_{|\alpha| = l} a_\alpha(\cdots) \partial^{\alpha}_x u,
		\]
		then the necessary condition is $k \geq l$.
	\item Analyticity is not good for propagation phenomena, or for shocks or singularities.

		Finally it is not good for regularisation. Consider for example $\Delta u = 0$, for $u \in C^2$. Then this means $u \in C^{\infty}$, which we do not get from CK.
\end{enumerate}

The good aspect of the Cauchy-Kovalevskaya is that it leads to classification.

\subsection{Classification}%
\label{sub:cfs}

\begin{definition}
	Given a linear differential operator
	\[
	p_u = \sum_{|\alpha| \leq k} a_\alpha(x) \partial^{\alpha}_x u,
	\]
	the \emph{principal symbol}\index{principal symbol} at $x$ is
	\[
	\sigma_p(x, \xi) = \sum_{|\alpha|= k}a_\alpha(x) \xi^{\alpha},
	\]
	for $\xi \in \mathbb{R}^n$, and the \emph{characteristic cone}\index{characteristic cone} at $x$ is
	\[
	\mathcal{C}_x = \{\xi \in \mathbb{R} \mid \sigma_p(x, \xi) = 0\}.
	\]
	Non-charactericity means
	\[
	\sigma_p(x, N(x)) \neq 0
	\]
	at $x \in \Sigma$.
\end{definition}

We can check this definition for the:
\begin{itemize}
	\item Laplace equation.
	\item Wave equation.
	\item Transport equation
		\[
		\sum_{j = 1}^n c_j(x) \partial_{x_j} u = 0.
		\]
	\item Heat equation.
	\item Schr\"odinger equation.
\end{itemize}

% lecture 9

These all have problems for CK:
\begin{itemize}
	\item For the Laplace equation, even though there is no characteristic surface, this means the Cauchy problem is ill-posed.
	\item The wave equation, although solvable by CK, wishes to be solved in a local, non-analytic way.
	\item The heat equation is ill-suited, as it is irreversible.
	\item The Schr\"odinger equation is a hybrid; it is a dispersive relation.
\end{itemize}

\newpage

\section{Functional Toolbox}%
\label{sec:ft}

Our motivation is to get access to Banach and Hilbertian geometric tools.

Moreover, some spaces are equal or close to physical quantities (e.g. energy) that is minimized or propogated in a PDE.

\subsection{H\"older Spaces}%
\label{sub:hs}

\begin{definition}
	Given $U \subseteq \mathbb{R}^n$ open, and $k \in \mathbb{N} \cup \{ \infty\}$ then
	\begin{itemize}
		\item $C^{k}(U)$ is the set of functions $u : U \to \mathbb{R}$ which are $k$-times differentiable, with $\partial^{\alpha}_x u$ continuous on $U$, for all $|\alpha| \leq k$.
		\item $C^{k}_b(U)$ is the set of function $u : U \to K$ in $C^{k}(U)$, and so that $\partial^{\alpha}_x u$ is bounded on $U$ for all $|\alpha| \leq k$.
		\item $C^{k}(\bar U) \subseteq C^{k}_b(U) \subseteq C^{k}(U)$ is the set of functions in $C^{k}_b(U)$, so that $\partial^{\alpha}_x u$ is uniformly continuous on $U$, for all $|\alpha| \leq k$.
	\end{itemize}
\end{definition}

\begin{remark}
	\begin{enumerate}
		\item[]
		\item The $\nabla$ notation is slighly incosistent on $C^k(\overline{\mathbb{R}^n})$ and $C^k(\mathbb{R}^n)$, even though these are the same.
		\item $C^{k}(U)$ is a Fr\'echet space.
	\end{enumerate}
\end{remark}

Both $C^{k}_b(U)$ and $C^{k}(\overline{U})$ are normed (Banach) vector spaces with
\[
\|u\|_{C^{k}_b(U)} = \|u\|_{C^k(\overline{U})} = \sup_{x \in U} \sup_{|\alpha| \leq k} |\partial^{\alpha}_x u(x)|.
\]
We can use H\"older space to interpolate between the $C^k$.

\begin{definition}
	Let $U \subseteq \mathbb{R}^n$ be open, $\gamma \in [0, 1]$, and $u : U \to \mathbb{R}$. The $u$ is \emph{H\"older continuous}\index{H\"older continuous} with respect to index $\gamma$ if there exists $C > 0$ such that for all $x, y \in U$,
	\[
	|u(x) - u(y)| \leq C |x - y|^{\gamma}.
	\]
	The space of such functions which are bounded is the $0$'th order H\"older space with index $\gamma$, $C^{0, \gamma}(\overline{U})$.

	For $k \in \mathbb{N}$, $C^{k, \gamma}(\overline{U})$ is defined as
	\[
		C^{k, \gamma}(\overline{U}) = \{u \in C^{k}(\overline{U}) \mid \partial^{\alpha}_x u \in C^{0, \gamma}(\overline{U}) \text{ for all } |\alpha| \leq k\}.
	\]\index{H\"older space}
\end{definition}

These spaces are Banach spaces, with the norm
\[
	\|u\|_{C^{k, \gamma}(\overline{U})} = \|u\|_{C^{k}(\overline{U})} + \sum_{|\alpha| \leq k} [\partial^{\alpha}_x u]_{C^{0, \gamma}(\overline{U})},
\]
where
\[
	[u]_{C^{0,\gamma}(\overline{U})} = \sup_{x \neq y \in U} \frac{|u(x) - u(y)|}{|x - y|^{\gamma}}.
\]
We have $\gamma \leq 1$, as if $\gamma > 1$, then we immediately get differentiability with derivative 0.

\subsection{Lebesgue Spaces}%
\label{sub:ls}

\begin{definition}
	Let $U \subseteq \mathbb{R}^n$ be open, and $p \in [1, +\infty]$. Then the global \emph{Lebesgue space}\index{Lebesgue space} $L^p()$ is the set of classes of equivalence (for almost-everywhere equality) of measurable functions $u$ such that $|u|^p$ is integrable:
	\[
	\int_U |u|^p < +\infty.
	\]
	The \emph{local Lebesgue space}\index{local Lebesgue space} $L^p_{\mathrm{loc}}(U)$ is the classes of equivalence of measurable functions $u$ such that $u \in L^p(V)$ for any $V \subseteq \subseteq U$.
\end{definition}

Here, $V \subseteq \subseteq U$ means that $V$ is an open set such that $\overline{V} = U$, and $\overline{V}$ is compact.

There are three key results:

\begin{enumerate}
	\item Monotone convergence theorem: if $f_n \geq 0$, and $f_n \uparrow$, then
		\[
		\sup \int f_n = \sup f_n.
		\]
	\item Fatou's lemma: if $f_n \geq 0$ measurable, then
		\[
		\int \liminf f_n \leq \liminf \int f_n.
		\]
	\item Dominated convergence theorem: if $f_n \to f$ a.e. and $|f_n| \leq g$ integrable, then
		\[
		\int f_n \to \int f.
		\]
	\item $L^p(U)$ is a Banach space, where for $p < \infty$,
		\[
		\|u\|_{L^p(U)} = \left( \int_u |u(x)|^p \diff x \right)^p,
		\]
		and for $p = \infty$,
		\[
		\|u\|_{L^\infty(U)} = \mathrm{esssup}_U |u|.
		\]
\end{enumerate}

To prove this, we can show a Cauchy sequence in $L^p$ has a subsequence converging almost-everywhere, and we can use Fatou's lemma to deduce $L^p$ convergence.

For $p = 2$, we have a Hilbert space, with
\[
\langle u, v\rangle = \int_U u v.
\]

\subsection{Weak (generalized) Derivatives}%
\label{sub:wd}

We say that $v$ is an \emph{$\alpha$-weak derivative}\index{$\alpha$-weak derivative} of $u$, denoted $D^\alpha u = v$, if for all $\phi \in C^{\infty}_c(U)$,
\[
\int_U u (\partial^{\alpha}_x \phi) = (-1)^{\alpha} \int_U v \phi.
\]
\begin{remark}
	\begin{enumerate}
		\item[]
		\item If $u \in C^{k}(U)$, $\partial^{\alpha}_x u$ for $|\alpha| \leq k$ is also an $\alpha$-weak derivative.
		\item The $\alpha$-weak derivative of $u$ is unique, as
			\[
				\int_U (v_1 - v_2) \phi = 0 \text{ for all }\phi \in C^{\infty}_c(U) \implies v_1 = v_2 \text{ in } L^{1}_{\mathrm{loc}}(U).
			\]
	\end{enumerate}
\end{remark}

\begin{definition}
	If $U \subseteq \mathbb{R}^n$ is open, $k \in \mathbb{N}$ and $p \in [1, +\infty]$, we say that $u \in W^{k, p}(U)$ (\emph{Sobolev space}\index{Sobolev space}) if $u \in L^p(U)$ and for all $|\alpha| \leq k$, $D^\alpha u \in L^p(U)$.

	Moreover $W^{k, p}_{\mathrm{loc}}(U)$ are $u \in L^1_{\mathrm{loc}}(U)$, which are in $W^{k, p}(V)$ for all $V \subseteq \subseteq U$.
\end{definition}

This is a Banach space, with norm
\begin{align}
	\|u\|_{W^{k, p}(U)} &= \left( \sum_{|\alpha| \leq k} \|D^\alpha u\|_{L^p(U)}^p \right)^{1/p}
\end{align}
for $p < \infty$, and
\[
\|u\|_{W^{k, \infty}(U)} = \sup_{|\alpha| \leq k} \|D^\alpha u\|_{L^\infty(U)}.
\]
For $p = 2$, we write
\[
W^{k, 2}(U) = H^{k}(U),
\]
as a Hilbert space.

We can also define $W^{k, p}_0(U)$ as the closure of $C_c^{\infty}(U)$ for the $W^{k, p}(U)$ norm, and analogously $H^{k}_0(U) = W_0^{k, 2}(U)$.

\begin{exbox}
	Consider $u(x) = |x|^{-s}$ in $B(0, 1) \subseteq \mathbb{R}^n$, for some $s < n$. Then $u \in L^1(B(0, 1))$

	For $s < n-1$, $u \in W^{1, 1}(B(0,1))$, and we can find $D_{x_1} u$. Also for $s < \frac{n-p}{p}$, this is in $W^{2, p}(B(0, 1))$.
\end{exbox}

% lecture 10

\subsection{Approximations in Sobolev Spaces}%
\label{sub:approx}

In this section we wish to approximate Sobolev functions by functions with classical derivatives.

\begin{definition}
	A \emph{standard mollifier}\index{standard mollifier} is a family $(\vphi_\eps)$, such that $\vphi_\eps \in C_c^{\infty}(\mathbb{R}^{n})$, $\mathrm{supp} \vphi_\eps \subseteq B(0, \eps)$, $\vphi_\eps \geq 0$ and
	\[
	\int_{\mathbb{R}^n} \vphi_{\eps}(x) \diff x = 1.
	\]
\end{definition}

\begin{proposition}
	Let $U \subseteq \mathbb{R}^n$ be open, and $p \in [1, +\infty]$. Then,
	\begin{enumerate}[\normalfont(i)]
		\item There exists a family of standard mollifiers.
		\item For $u \in L^1_{\mathrm{loc}}(U)$, define $u_\eps = \vphi_\eps \ast u$. This mollification satisfies $u_\eps \in C_c^{\infty}(U_\eps)$, where $U_\eps = \{x \in U \mid d(x, \partial U) > \eps\}$.

			Moreover $u_\eps \to u$ almost-everywhere.
		\item If $u \in C^k(U)$, then $\partial^{\alpha}_x u_\eps \to \partial^{\alpha}_x u$ uniformly on compact subsets of $U$, for any $|\alpha| \leq k$.
		\item If $u \in W^{k, p}(U)$, then $u_\eps \to u$ in $W^{k, p}_{\mathrm{loc}}(U)$, i.e. convergence in $W^{k,p}(V)$ for any $V \subseteq \subseteq U$.
		\item If $U$ is bounded and $u \in W^{k, p}(U)$, then there exists $(u_j)$, with $u_j \in C^{\infty}(U) \cap W^{k, p}(U)$ so that $u_j \to u$ in $W^{k, p}(U)$ (global approximation not uniform near the boundary).
		\item If $U$ is bounded and $\partial U$ is locally the graph of a Lipschitz function, then for $u \in W^{k, p}(U)$, there exists $(u_j)$ where $u_j \in C^{\infty}(\bar U)$ (which implies $u_j \in W^{k, p}(\Omega)$) so that $u_j \to u$ in $W^{k, p}(U)$ (global approximation in $W^{k,p}(U)$ by smooth functions uniformly regular at $\partial U$).
	\end{enumerate}
\end{proposition}

\begin{proofbox}
	

	(i) We can use, for instance
	\[
	\vphi(x) = 
	\begin{cases}
		C \exp \left( - \frac{1}{1 - |x|^2} \right) & |x| \leq 1, \\
			0 & |x| > 1.
	\end{cases}
	\]
	We choose $C > 0$ such that $\int \vphi = 1$, and then scale:
	\[
	\vphi_\eps(x) = \eps^{-k} \vphi \left( \frac{x}{\eps} \right).
	\]
	(ii) Importantly, translations are continuous in $L^1$, i.e.
	\[
		\tau_\eps u = u(\cdot + \eps) \overset{L^1}\to u.
	\]
	We can check this by density of simple functions. Hence $u_\eps \to u$ in $L^1_{\mathrm{loc}}(U)$, for $\eps < \eps_0$. We can also use Lebesgue differentiation theorem.

	(iii) This is a standard calculation, by integration by parts:
	\[
	\partial^{\alpha}_x u_\eps = \int \partial^{\alpha}_x u(y) \vphi_\eps(x - y) \diff y = \cdots.
	\]

	(iv) We repeat (ii) on each weak derivative.

	(v) We use a covering argument. We decompose $U$ into $U_{l} = \{x \in U \mid d(x, \partial U) > 1/l\}$, and define
	\[
	V_l = U_{l + 3} \setminus \overline{U_{l+1}}.
	\]
	Then,
	\[
	\bigcup_{l \geq 1} V_l \cup (V_0) = U,
	\]
	where $V_0 = U \setminus \bigcup_{l \geq 1} V_c$.

	We now take partitions of unity $(\xi_l)$, subordinate to $(V_l)$ i.e. $\xi_l \in C_c^\infty(V_l)$, and
	\[
	\sum_{l \geq 0} \xi_l = 1.
	\]
	Then for each $l > 0$, we pick $\eps_l  0$ so that
	\[
	u^l = \vphi_{\eps_l} \ast (\xi_l u)
	\]
	is supported in
	\[
	W_l = U_{l + 4} \setminus \overline{U_l},
	\]
	and is $2^{-l-1} \cdot \delta$ close to $\xi_l u$ in $W^{k, p}(\cdots)$. Then we define
	\[
	\tilde u = \sum_{l = 0} u^{l},
	\]
	which satisfies
	\begin{align*}
		\|u - \tilde u\|_{W^{k, p}(U)} &= \left\| \sum_{l \geq 0} \xi_{l} u - \sum_{l \geq 0} \vphi_{\eps_l} \ast (\xi_l u) \right\|_{W^{k, p}(U)} \\
					       &\leq \sum_{l \geq 0} 2^{-l-1} \delta \leq \delta.
	\end{align*}

	(vi) For each $x \in \partial U$, there is $r_x > 0$ such that $\partial U \cap B(x, r_0)$ is the graph of a Lipschitz function. By compactness of $\partial U$ (since $U$ is bounded), we get a finite cover
	\[
	\partial U \subseteq \bigcup_{l = 1}^L (\partial U \cap B(x^l, r_l)).
	\]
	Hence let us write
	\[
	U = V_0 \cup \bigcup_{l = 1}^L V_l,
	\]
	where $V_l = U \cap B(x^l, r_l)$. Then on each $V_l$ in $B(x^l, r_l)$ we write the boundary as a graph of a Lipschitz function. Without loss of generality, say $x_n = \Gamma(x_1, \ldots, x_{n-1})$ defines $\partial U \cap B(x^l, r_l)$, where $\Gamma$ is Lipschitz.

	Then, there exists $\lambda \in \mathbb{R}_+$ such that for all $x \in \partial U \cap B(x^l, r_l)$, and for all $\eps  >0$ small enough,
	\[
		B(x + \lambda \eps e_n, \eps) \subseteq U.
	\]
	Then,
	\[
	\vphi_{\hat \eps} \ast (\tau_{\lambda \eps e_n} u)
	\]
	is well-defined for all $\hat \eps < \eps$ small, and for $\eps \ll 1$, $\hat \eps \ll \eps$, this constructs $u_l$ such that
	\[
	\|u^l - u\|_{W^{k, p}(U \cap B(x^l, r_l)} \leq \frac{\delta}{k+1}.
	\]
	We can then recontruct, by taking $(\xi_l)$ a partition of unity subordinate to $(V_l)$, and letting
	\[
	v = \sum_{l = 0}^L \xi_l u^l.
	\]
	This satisfies $\|v - u\|_{W^{k, p}(U)} \leq \delta$, again by triangle inequality.
\end{proofbox}

% lecture 11

\subsection{Extensions and Traces}%
\label{sub:ext_tr}

\begin{theorem}[Extensions of $W^{1, p}$ functions]
	Given $U \subseteq \mathbb{R}^n$ open and bounded with $C^1$ boundary, and $V \subseteq \mathbb{R}^{n}$ open and bounded such that $U \subseteq \subseteq V$, if $p \in [+1, \infty]$ then there exists an extension operator, which is linear and bounded
	\[
	E : W^{1, p}(U) \to W^{1, p}(\mathbb{R}^n)
	\]
	 such that $\mathrm{supp} E(u) \subseteq V$ for $u \in W^{1, p}(U)$, and $E(u)|_{U} = u$ almost everywhere.
\end{theorem}

\begin{remark}
	Bounded means there is $C = C(U, V, p) > 0$ such that
	\[
	\|E(u)\|_{W^{1, p}(\mathbb{R}^n)} \leq C \|u\|_{W^{1, p}(U)}.
	\]
\end{remark}

\begin{proofbox}
	Since $\partial U$ is $C^1$, it is locally the graph of a $C^1$ function. So for all $x \in \partial U$, there is $B(x, r)$ so that $\partial U \cap B(x, r)$ can be written as
	\[
	x_n = \Gamma(x_1, \ldots, x_{n-1}),
	\]
	for some $\Gamma \in C^1$. Then we can write
	\[
		U \cap B(x, r) = \{x' \in B(x, r) \mid x_n' > \Gamma(x_1', \ldots, x_{n-1}')\}.
	\]
	Now we wish to flatten out the boundary. Take $\Phi : B(x, r) \to B(y, r')$, where $y = (\tilde x, 0)$, and $\tilde x = (x_1, \ldots, x_{n-1})$. We can define $\Phi(x') = y'$ where $y_n' = x_n' - \Gamma(\tilde x')$, and $\tilde y' = \tilde x'$.

	Then $\Phi$ maps $\partial U \cap B(x, r)$ into $\{y_n' = 0\}$, and $U \cap B(x, r)$ into $\{y_n' > 0\}$. Also $\Phi$ is $C^1$ and has $\det D \Phi = 1$.

	So we may take $\Psi = \Phi^{-1}$ on $B(y, r'')$, so $\Psi(y') = x'$.

	Take $u \in C^{\infty}(\overline{U}) \cap W^{1, p}(U)$. Then locally around $x \in \partial U$, $v = u \circ \Psi$ is defined on
	\[
		B_+ = B(y, r'') \cap \{y_n' > 0\}.
	\]
	Define (higher-order) symmetrization $\bar v(y')$ on $B(y, r'')$ by
	\[
	\bar v = v,
	\]
	on $B_+$, and
	\[
	\bar v(y') = - 3 v(\tilde y', -y_n') + 4 v(\tilde y', - y_n'/2).
	\]
	This is continuous at $y_n' = 0$, and $\partial \bar v$ is continuous at $y'_n = 0$. This can be defined on $B_- = B(y, r'') \cap \{y_n' < 0\}$.

	We can check that $\bar v \in C^{1}$ on $B(y, r'')$, and
	\[
	\|\bar v\|_{W^{1, p}(B(y, r''))} \leq C \|v\|_{W^{1, p}(B_+)}.
	\]
	This is done by relating $\partial \bar v$ to $\partial v$. Define $\bar u = \bar v \circ \Phi$ on $B(x, r''')$, for $r''' > 0$.

	Since $\Phi \in C^1$, $\bar u$ is $C^1$ on $B(x, r''')$ and
	\[
	\|\bar u\|_{W^{1, p}(B(x, r'''))} \leq C' \|u\|_{W^{1,p}(U \cap B(x, r'''))}.
	\]
	Now we want to reconstruct the entire function. Take a cover $V_l = B(x^l, r_l)$ for $x^l \in \partial U$, for $l = 1, \ldots, L$, and say
	\[
	U \setminus \left( \bigcup_{l= 1}^L V_l \right) \subseteq V_0 \subseteq \subseteq U.
	\]
	Take $(\xi_l)$ a partition of unity subordinate to $(V_l)$. Let $u^0 = u$ on $V_0$ and $u^l$ as the symmetrisation on $l = 1, \ldots, L$. Then let
	\[
	Eu = \sum_{l = 0}^{L} \xi_l u^{l}.
	\]
	Then $\mathrm{supp} Eu \subseteq V = \bigcup V_l \subseteq U$, and
	\[
	\|Eu\|_{W^{1,p}} \leq \sum_{l = 0}^L \|u^l\|_{W^{1,p}(V_l)} = C'' \|u\|_{W^{1,p}(U)}.
	\]
	We can now get rid of $u \in C^{\infty}(\overline{U})$, by using a density argument.

	Let $u_j \in C^{\infty}(\overline{U})$ such that $u_j \to u$ in $W^{1, p}(U)$. $E$ is linear and bounded, so $(E u_j)$ is Cauchy. So $E u_j \to Eu$ in $W^{1, p}(V)$. Moreover the limit does not depend on the approximation as if $u_j^1, u_j^2 \to u$, then
	\[
	\|E(u_j^1 - u_j^2)\|_{W^{1, p}(V)} \to 0.
	\]
\end{proofbox}

\begin{remark}
	If we want to extend in $W^{k, p}(U)$, in our proof structure we need $\partial U \in C^k$, and a higher order symmetrisation,
	\[
	\bar v(y') = \sum_{m = 1}^k c_m v(\tilde y', - y_n'/m),
	\]
	and find suitable coefficients $c_m$.
\end{remark}

\begin{theorem}
	Let $U \subseteq \mathbb{R}^n$ be open and bounded and with $\partial U$ $C^1$. Let $p \in [1, +\infty]$. Then there exists a linear bounded trace operator $T : W^{1, p}(U) \to L^{p}(\partial U)$ so that $T(u) = u|_{\partial U}$ for $u \in W^{1, p}(U) \in C^{\infty}(\overline{U})$.
\end{theorem}

\begin{remark}
	\begin{enumerate}
		\item[]
		\item As $u \in C^{\infty}(\overline{U})$, we can extend $u$ on $\partial U$ by uniform continuity.
		\item $T$ is bounded means that there is $C = C(U, p)$ so that
			\[
			\|Tu\|_{L^p(\partial U)} \leq C \|u\|_{W^{1,p}(U)}.
			\]
		\item If $u \in W^{k, p}(U)$, we can define the trace of $Du, D^2u, \ldots, D^{k-1}u$.
		\item If $u \in W^{1,p}_{0}(U)$, i.e. within
			\[
			\overline{C_c^\infty(U)}^{W^{1, p}(U)},
			\]
			then $Tu = 0$ on $\partial U$ almost everywhere, since if $u_j \to u$ for $u_j \in C_c^{\infty}(U)$ then $Tu_j = 0$, and $T$ is bounded.

			In fact, the converse is true: if $Tu = 0$ for $u \in W^{1, p}(U)$, then $u \in W^{1,p}_0(U)$.
		\item This theorem is optimal for $p = 1$, but for $p \in (1, +\infty)$ the loss of derivatives is only $1/p$. In codimension $m$, the loss is $m/p$.
	\end{enumerate}
	
\end{remark}

\begin{proofbox}
	We use the same structure again. To construct $T$, we use localization, flattening, deconstruction, and then relax $C^{\infty}(\overline{U})$.

	In the flat boundary with the whole space, to show it is $L^p$ we have
	\begin{align*}
		\int_{\mathbb{R}^{n-1}} |v(\tilde y, 0)|^p \diff \tilde y &= \int_{\mathbb{R}^{n-1}} \int_0^{\infty} \partial y_n |v(\tilde y, y_n)|^p \diff \tilde y \diff y_n \\
									  &= \int_{\mathbb{R}_+^n} p|v(y)|^{p-1} (\partial y_n v)(y) \sgn(v) \diff y.
	\end{align*}
\end{proofbox}

% lecture 12

\subsection{Sobolev Inequalities}%
\label{sub:sobineq}

Our goal is to integrate weak integrated regularity with classical regularity.

We start with $W^{1, p}$, which $W^{k, p}$ is found inside. For $p > n$ we find H\"older functions.

\begin{lemma}
	Let $n \geq 2$, and $f_1, \ldots, f_n \in L^{n-1}(\mathbb{R}^{n-1})$. Then let
	\[
	f(x) = \prod_{i = 1}^n f_i(\tilde x_i),
	\]
	where $\tilde x_i = (x_1, \ldots, x_{i-1}, x_{i+1}, \ldots, x_n)$. This is integrable with
	\[
	\|f\|_{L^1(\mathbb{R}^n)} \leq \prod_{i = 1}^n \|f_i\|_{L^{n-1}(\mathbb{R}^{n-1})}.
	\]
\end{lemma}

\begin{proofbox}
	Our base case is $n = 2$. We use Fubini's; if $f(x) = f_1(x_2) f_2(x_1)$, then
	\[
	\|f\|_{L^1(\mathbb{R}^2)} = \|f_1\|_{L^1(\mathbb{R})} \|f_2\|_{L^1(\mathbb{R})}.
	\]
	Now we propagate from $n$ to $n + 1$. Let $f(x) = f_{n+1}(\tilde x_{n_1}) F(x)$, where $F(x) = f_1(\tilde x_1) \cdots f_n(\tilde x_n)$.

	We apply step $n$ with $x_{n+1}$ frozen, so
	\[
	\int_{\mathbb{R}^n} |f(\cdot, x_{n+1})| \diff x_1 \cdots \diff x_n \leq \|f_{n+1}\|_{L^n(\mathbb{R}^n)} \|F(\cdot, x_{n+1})\|_{L^{n/(n-1)}}
	\]
	by H\"older. Then note
	\[
	F(\cdot, x_{n+1})^{n/(n-1)} = \prod_{i=  1}^n \tilde f_i,
	\]
	where $\tilde f_i(\cdot) = f_i(\cdot, x_{n+1})^{n/(n-1)}$. Then this has norm at most
	\begin{align*}
	& \qquad\|f_{n+1}\|_{L^{n}(\mathbb{R}^{n})} \left( \prod_{i = 1}^n \|\tilde f_i\|_{L^{n-1}(\mathbb{R}^{n-1})} \right)^{(n-1)/n} \\
	&\leq \|f_{n_1}\|_{L^n} \prod_{i = 1}^n \|f_i(\cdot, x_{n+1})\|_{L^n(\mathbb{R}^n)}.
	\end{align*}
	Now we integrate this with respect to $x_{n+1}$, so
	\begin{align*}
		\int_{\mathbb{R}} LHS \diff x_{n+1} &\leq \|f_{n+1}\|_{L^n} \left( \prod_{i = 1}^n \int_{x_{n+1}} \|f_n(\cdot, x_{n+1})\|_{L^n}^n \right)^{1/n} \\
						    &\leq \prod_{i = 1}^{n+1} \|f_i\|_{L^{n}(\mathbb{R}^{n})},
	\end{align*}
	again by H\"older.
\end{proofbox}

\begin{theorem}[Gagliardo-Norenberg-Sobolev]
	Globally in $\mathbb{R}^n$, given $p \in [1, n)$, there is $C = C(n, p) > 0$ so that
	\[
	\|u\|_{L^{p^{\ast}}(\mathbb{R}^n)} \leq C \|Du\|_{L^p(\mathbb{R}^n)},
	\]
	for all $u \in W^{1, p}(\mathbb{R}^n)$, where $\frac{1}{p} = \frac{1}{n} + \frac{1}{p^{\ast}}$.

	Locally away from a boundary, given $U \subseteq \mathbb{R}^n$ open and bounded, then there is $C = C(U, n, p) > 0$ such that
	\[
	\|u\|_{L^{p^\ast}(U)} \leq C \|Du\|_{L^p(U)},
	\]
	for all $u \in W^{1,p}_0(U)$.

	We also have a local version up to the boundary: let $U \subseteq \mathbb{R}^n$ be open and bounded with $C^1$ boundary. Then there is $C = C(U, n, p) > 0$ such that
	\[
	\|u\|_{L^{p^\ast}(U)} \leq C \|u\|_{W^{1, p}(U)},
	\]
	for all $u \in W^{1, p}(U)$.
\end{theorem}

\begin{remark}
	\begin{enumerate}
		\item[]
		\item Note $p^{\ast} > p$, so this shows higher integrability.
		\item $Du$ is not changed by adding a constant to $u$, so $u \in L^p$ is needed in $\mathbb{R}^n$ to get $u \to 0$.
	\end{enumerate}
\end{remark}

\begin{proofbox}
	The idea is to write $u$ as an integral of partial derivatives, then use the previous lemma.

	First we consider $p = 1$, and $u \in C_c^\infty(\mathbb{R}^n)$, in the global version. For all $i$,
	\[
	u(\bar x) = \int_{-\infty}^{\bar x_i} \partial_{x_i} u(x_1, \ldots, x_{i-1}, y_i, x_{i+1}, \ldots, x_n) \diff y_i.
	\]
	Then $|u(\bar x)| \leq g_i(\tilde x_i)$, where
	\[
	g_i(\tilde x_i) = \int_{-\infty}^{+\infty} |\partial_{x_i} u(\tilde x_i, y_i)| \diff y_i.
	\]
	Let $f(x) = |u(x)|^{n/(n-1)} \leq \prod f_i(\tilde x_i)$, where
	\[
	f_i(\tilde x_i) = g_i(\tilde x_i)^{1/(n-1)}.
	\]
	Then we find
	\begin{align*}
		\|f\|_{L^1} &= \|u\|^{n/(n-1)}_{L^{n/(n-1)}} \leq \prod_{i = 1}^n \|f_i\|_{L^{n-1}} \\
			    &= \prod_{i = 1}^n \|g_i\|_{L^1}^{1/(n-1)} = \prod_{i = 1}^n \|\partial x_i u\|_{L^1}^{1/(n-1)} \\
			    &\leq \|\nabla_U\|_{L^1}^{n/(n-1)}.
	\end{align*}
	Then note that $p^{\ast} = n/(n-1)$.

	Now we wish to relax to $p \in (1, n)$. Apply the $p = 1$ step to $v = |u|^{\gamma}$, where
	\[
	\gamma = \frac{p(n-1)}{n - p}.
	\]
	Then $\partial_{x_i} v = \gamma \sgn(u) |u|^{1 - \gamma} \partial_{x_i} u$, and
	\begin{align*}
		\|v\|_{L^{n/(n-1)}} &\leq \|u\|^{\gamma}_{L^{pn/(n-p)}} = \prod_{i = 1}^n \|\gamma |u|^{\gamma - 1} \partial_{x_i} u\|_{L^1}^{1/n} \\
				    &\leq \gamma \prod_{i = 1}^n \left( \|u\|_{L^{pn/(n-p)}}^{n(p-1)/(n-p)} \|\nabla u\|_{L^p} \right)^{1/n}.
	\end{align*}
	Collecting everything,
	\[
	\|u\|_{L^{pn/(n-p)}}^{\gamma - n(p-1)/(n-p)} \leq \gamma \|\nabla u\|_{L^p}.
	\]
	The top becomes $1$, and the bottom becomes $p^{\ast}$. Now $u \in C_c^{\infty}(\mathbb{R}^n)$ is reduced by using density of $C_c^{\infty}(\mathbb{R}^n)$ in $W^{1, p}(\mathbb{R}^n)$, by localizing to a small enough ball and then mollifying.

	Now consider the local version in $W^{1,p}_0(U)$. Apply the fact that $W^{1, p}_0(U) = \overline{C_c^{\infty}(U)}^{W^{1,p}}$, and the previous calculation for $u \in C^{\infty}_c(U)$.

	For the local version, we know there exists an extension operator $E : W^{1,p}(U) \to W^{1, p}(V)$. Then $Eu \in W^{1, p}(\mathbb{R}^n)$. Applying the global inequality to $Eu$,
	\begin{align*}
		\|u\|_{L^{p^{\ast}}(U)} &= \|Eu\|_{L^{p^{\ast}}(U)} \leq \|Eu\|_{L^{p^{\ast}}(\mathbb{R}^n)} \leq C \|Eu\|_{W^{1,p}(\mathbb{R}^{n})} \\
					&= C \|Eu\|_{W^{1,p}(V)} \leq C C' \|u\|_{W^{1,p}(U)}.
	\end{align*}
\end{proofbox}

\begin{theorem}[Morrey's Inequality]
	Let $p \in (n, +\infty).$ Then there is $C = C(n, p) > 0$ so that
	\[
	\|u\|_{C^{0, \gamma}(\mathbb{R}^n)} \leq C \|u\|_{W^{1,p}(\mathbb{R}^n)}
	\]
	for $u \in C^{\infty}_c(\mathbb{R}^n)$, $\gamma \in (0, 1)$.

	In other words, any $u \in W^{1,p}(\mathbb{R}^n)$ has a $C^{0, \gamma}$ representative.

	Locally, if $U \subseteq \mathbb{R}^n$ is open and bounded, and $\partial U$ is $C^1$, then there is $C  = C(U, n, p) > 0$ such that
	\[
	\|u\|_{C^{0, \gamma} (U)} \leq C \|u\|_{W^{1,p}(U)}.
	\]
\end{theorem}

\begin{proofbox}
	The main idea is to show that $u$ is locally pointwise close to its averages.

	If $\bar x \in \mathbb{R}^n$, and 
	\[
		Q_r(\bar x) = \{ |x_i - \bar x_i| \leq r/2 \text{ for all } i \},
	\]
	then we can define
	\[
	\bar u_{\bar x, r} = \frac{1}{|Q_r(\bar x)|} \int_{Q_r(\bar x)} u.
	\]
	We will show that $|u(\bar x) - \bar u_{\bar x, r}| \leq r^{\cdot} \|u\|_{W^{1,p}}$.
% lecture 13

	Alright let's start again. The global condition implies the local condition by the extension theorem. Then from density, there exists $u_j \in C_c^{\infty}$ such that $u_j \to u$ in $W^{1, p}(\mathbb{R}^n)$.

	Then $(u_j)$ is Cauchy in the uniform norm, so $u_j \to u$ for $u \in C^{0, \gamma}$.

	Globally in $\mathbb{R}^n$ for $u \in C_c^\infty(\mathbb{R}^n)$, for $\bar x \in \mathbb{R}^n$ let
	\[
		Q_r(\bar x) = \{ |x_i - \bar x_i| \leq r/2 \mid i = 1, \ldots, n\}.
	\]
	So we can define
	\[
	\bar u_{\bar x, r} = r^{-n} \int_{Q_r(\bar x)} u(x) \diff x.
	\]
	The difference is
	\begin{align*}
		|u(\bar x) - \bar u_{\bar x, r}| &= \left| r^{-n} \int_{Q_r(\bar x)} (u(x) - u(\bar x)) \diff x\right| \\
						 &\leq r^{-n} \int_{Q_r(\bar x)} |u(x) - u (\bar x)| \diff x \\
						 &\leq r^{-n} \int_0^1 \int_{Q_r(\bar x)} |x - \bar x| |\nabla u(\bar x + t(x - \bar x))| \diff x \diff t \\
						 &\leq \frac{r^{1-n}}{2} \int_0^1 t^{-n} \left( \int_{Q_{tr}(\bar x)} |\nabla u(y)| \diff y \right) \diff t \\
						 &\leq \frac{r^{1-n}}{2} \int_0^1 t^{-n} \|\nabla u\|_{L^p(Q_{tr}(\bar x))} |Q_{tr}(\bar x)|^{1/q} \diff t \\
						 &\leq \|\nabla u\|_{L^p(\mathbb{R}^n)} \frac{r^{1 -n + n/q}}{2} \int_0^1 t^{-n + n/q} \diff t \\
						 &\leq \|\nabla u\|_{L^p(\mathbb{R}^n)} \frac{r^{1 - n/p}}{2} \frac{1}{(1 - n/p)}.
	\end{align*}
	Now we take a supremum bound, with $r = 1$, to get that
	\begin{align*}
		|u(\bar x)| &\leq |u(\bar x) - \bar u_{\bar x, 1}| | + |\bar u_{\bar x, 1}| \\
			    &\leq \frac{1}{2(1 - n/p)} \|\nabla u\|_{L^p(\mathbb{R}^n)} + \int_{Q_1(\bar x)} |u(x)| \diff x.
	\end{align*}
	The last integral is at most $\|u\|_{L^p(\mathbb{R}^n)}$. So
	\[
	|u(\bar x)| \leq C \|u\|_{W^{1, p}(\mathbb{R}^n)}.
	\]
	Consider $x, y \in \mathbb{R}^n$, with $|x - y| =  r/2$. Then $Q_r(x)$ contains $y$, and $Q_r(y)$ contains $x$, so
	\begin{align*}
		|u(x) - u(y)| & \leq |u(x) - \bar u_{x, r}| + |u(y) - \bar u_{y, r}| + |\bar u_{x, r} - \bar u_{y, r}|.
	\end{align*}
	The first and second integrals are at most
	\[
	\frac{r^{1 - n/p}}{2(1 - n/p)} \|u\|_{W^{1,p}(\mathbb{R}^n)}.
	\]
	The third integral is at most
	\begin{align*}
		I_3 &\leq r^{-n} \int_{Q_r(x)} |u(z + (y - x)) - u(z)| \diff z \\
		    &\leq r^{-n} \int_{Q_r(x)} \int_0^1 |y - x| |\nabla u(z + t(y - x))| \diff t \diff z \\
		    &\leq \frac{r^{1-n}}{2} \int_0^1 \int_{(1 - t)Q_r(x)+ tQ_r(y)} |\nabla u(\tilde z)| \diff \tilde z \\
		    &\leq \frac{r^{1-n}}{2} \left( \int_0^1 |(1 - t) Q_r(x) + t Q_r(y)|^{1/q} \diff t \right) \|\nabla u\|_{L^{p}(\mathbb{R}^n)} \\
		    &\leq \frac{r^{1 - n/p}}{2} \left( \int_0^1 t^{n/q} \diff t \right) \|\nabla u\|_{L^p(\mathbb{R}^n)} \\
		    &\leq \frac{r^{1-n/p}}{2(1 + n/q)} \|\nabla u\|_{L^p(\mathbb{R}^n)}.
	\end{align*}
	In conclusion,
	\[
	\|u\|_{C^{0, \gamma}(\mathbb{R}^n)} \leq C \|u\|_{W^{1,p}(\mathbb{R}^n)},
	\]
	where $\gamma = 1 - n/p$.
\end{proofbox}

\subsection{Compactness of Sobolev Spaces}%
\label{sub:cpt_sob}

\begin{theorem}[Rellich-Kondrashov]
	Given $U \subseteq \mathbb{R}^n$ open, bounded with $C^1$ boundary and $p \in [1, +\infty)$, then $W^{1, p}(U)$ is compactly embedded in $L^q(U)$ for $q \in [1, p^{\ast})$. We write
	\[
	W^{1,p}(U) \subseteq \subseteq L^q(U).
	\]
	In other words, bounded subsets of $W^{1,p}(U)$ are relatively compact.
\end{theorem}

\begin{proofbox}
	We know the Arzel\'a-Ascoli theorem: if a set of functions $K \subseteq \mathbb{R}^n \to \mathbb{R}$ is equicontinuous and equibounded, then it is relatively compact in the uniform norm.

	Moreover $W^{1, p}(U) \subseteq L^q(U)$ by Sobolev inequalities. Indeed, for $q < p^{\ast}$,
	\[
	L^q \leq (L^p)^{\cdot} (L^{p^{\ast}})^{\cdot \cdot},
	\]
	for $U$ bounded.

	Since we have a metric space, we can prove compactness via sequences. Consider $u_j \in W^{1, p}(U)$ bounded. Then let $v_j = E u_j$ bounded in $W^{1, p}(\mathbb{R}^n)$ with compact support $V \supseteq \supseteq U$ and $\bar V$ compact. Let $(\vphi_{\eps})$ be standard mollifiers. Define
	\[
	v_j^{\eps} = \vphi_\eps \ast v_j,
	\]
	which has support uniformly included in $\tilde V$.

	To show the first claim, note that $v_j^{\eps} \to v_j$ uniformly in $j \geq 1$, in $L^q(\mathbb{R}^n)$. The proof, by density and the fact that $v_j$ is smooth, is
	\begin{align*}
		|v_j^{\eps}(x) - v_j(x)| &= \left| \int_{B(0,1)} \vphi(y) [v_j(x - \eps y) - v_j(x)] \diff y \right| \\
					 &\leq \eps \int_{B(0, 1)} \vphi(y) \int_0^1 |\nabla v_j(x - \eps ty)| \diff t \diff y,
	\end{align*}
	so overall,
	\begin{align*}
		\int_{\mathbb{R}^n} |v_j^{\eps}(x) - v_j(x)| \diff x &\leq \eps \int_{B(0, 1)} \vphi(y) \int_0^1 \int_{\mathbb{R}^n} |\nabla v_j(x - t \eps y) |\diff t \diff x \diff y \\
								     &\leq \eps \|\nabla v_j\|_{L^1(\mathbb{R}^n)} \\
								     &\leq C \eps \|\nabla v_j\|_{L^p(\mathbb{R}^n)}.
	\end{align*}
	By interpolation, we get
	\[
	\|v_j^{\eps} - v_j\|_{L^{p^{\ast}}(\mathbb{R}^n)}
	\]
	is bounded by Sobolev. So by Holder inequality,
	\[
	\|v_j^\eps - v_j\|_{L^q} \leq C \eps^{\theta} \|v_j\|_{W^{1,q}(\mathbb{R}^n)},
	\]
	where $\theta$ is so that $\frac{1}{q} = \theta + \frac{1 - \theta}{p^{n}}.$

	For the second claim, for fixed $\eps > 0$, $(v_j^{\eps})$ satisfies the assumptions of Arzel\'a-Ascoli, so
	\begin{align*}
		\|v_j^{\eps}\|_{L^\infty} &\leq \|\vphi_\eps\|_{L^\infty} \|v_j\|_{L^1} \leq C \eps^{-n} \|v_j\|_{L^p}, \\
		\|\nabla v_j^\eps\|_{L^\infty} &\leq \|\nabla \vphi_\eps\|_{L^\infty} \|v_j\|_{L^1} \leq C \eps^{-n - 1} \|v_j\|_{L^p}.
	\end{align*}
	We do a diagonal argument. Take $\delta_n \to 0$. Choose $\eps_n$ small enough so that $\|v_j^{\eps_m} - v_j\|_{L^q} \leq \delta_m/2$. Then apply AA to give a subsequence and so
	\[
	\|v_{j_k}^{\eps} - v_{j_l}^{\eps}\|_{L^q} \leq \frac{\delta_m}{2},
	\]
	for $k, p \geq L$. We induct and re extract our subsequence so that
	\[
	\|v_{j_k} - v_{j_l}\|_{L^q} \leq \delta_m.
	\]
\end{proofbox}

% lecture 14

\newpage

\section{Ellipticity}%
\label{sec:ell}

We let $U \subseteq \mathbb{R}^n$ be open, non-empty, bounded and $\partial U$ being $C^1$.

\subsection{Notion of Ellipticity}%
\label{sub:noe}

We have learnt that ellipticity for a linear differential operator means there are no characteristic hypersurfaces, i.e. $\sigma_p(x, \xi) \neq 0$ for all $x \in U$, $\xi \neq 0$.

For a particular case, take $a_{ij}, b_i , c : U \to \mathbb{R}$ and let
\[
Lu = - \partial_{x_i} (a_{ij} \partial x_j u) + b_i \partial_{x_i} u + cu.
\]
Here we are using Einstein summation notation. This is the \emph{divergence form}\index{divergence form}, as the higher-order term looks like a divergence. The non-divergence form is
\[
Lu = - a_{ij} \partial^2_{x_i x_j} u + \tilde b_i \partial_{x_i} u + cu.
\]
When $a_{ij}$ is differentiable, one can navigate between the two forms:
\[
\tilde b_i = \partial_{x_j}(a_{ij}) + b_i.
\]
When we have
\[
\partial^2_{x_i x_j} u = \partial^2_{x_j x_i} u,
\]
then it is possible to rewrite the higher-order term with a symmetric matrix:
\[
\partial_{x_i}(a_{ij} \partial_{x_j} u) = \partial x_i (a_{ij}^s \partial_{x_j} u) + \partial_{x_i} (a_{ij}^{as}) \partial_{x_j} u,
\]
and we have
\[
a_{ij} \partial^2_{x_i x_j u} = a_{ij}^s \partial^2_{x_i x_j} u.
\]
\begin{definition}
	$L$ of this form is \emph{elliptic}\index{elliptic} if $a_{ij}(x) \xi_i \xi_j > 0$ for all $x \in U$, $\xi \in \mathbb{R}^n_{\ast}$.

	$L$ is \emph{uniformly elliptic}\index{uniformly elliptic} if there exists $\theta > 0$ so that $a_{ij}(x) \xi_i \xi_j \geq \theta |\xi|^2$ for all $x \in U$, $\xi \in \mathbb{R}^n$.
\end{definition}

The goal of this chapter is to solve $Lu = f$ with uniform ellipticity, where we prescribe $u_{|\partial U} = 0$. This is a Dirichlet condition.

\subsection{Solving the Dirichlet Problem}%
\label{sub:sdp}

The idea is to reformulate the Dirichlet problem as a geometric problem: more explicitly, we are representing a linear form in a Hilbert space.

We let $L$ be in divergence form. The weak or dual formulation is as follows:

Here is an observation. If $u \in C^2(\bar U)$ solves this problem, then for any $v \in C^2(\bar U)$ and $v|_{\partial U} = 0$, we have by integrating $Lu=  f$ against $v$,
\begin{align*}
	\int_U f v &= \int_U \left(- \partial_{x_i} (a_{ij} \partial_{x_j} u)) v + b_i (\partial_{x_i} u) v + c uv \right) \\
		   &= \int_U \left( a_{ij} (\partial_{x_i} u) (\partial_{x_j} v) + b_i (\partial_{x_i} u) v + c u v \right) = B[u, v],
\end{align*}
where the equation $B[u, v] = \langle f, v\rangle$ still makes sense for $u, v \in H^1_0(U)$.

\begin{definition}
	$u \in H^1_0(U)$ is a \emph{weak solution}\index{weak solution} to the Dirichlet problem if for all $v \in H^1_0(U)$,
	\[
		B[u, v] = \langle f, v\rangle,
	\]
	for $f \in L^2(U)$.
\end{definition}

\begin{remark}
	We should take $f \in H^{-1}_0(U) = (H^1_0(U))^{\ast}$.
\end{remark}

\begin{proposition}
	$u \in H^1_0(U) \cap C^2(\bar U)$ is a weak solution for $f \in C^0(U)$ if and only if $u$ is a classical solution to $(\ast\ast)$.
\end{proposition}

\begin{remark}
	We always want our weakened notions of solutions to agree with the stronger ones when enough regularity is available.
\end{remark}

\begin{proofbox}
	If $u$ is classical, then we may do our integration by parts and hence $u \in H^1_0(U)$ is a weak solution.

	For the forwards direction, we test $(\ast\ast\ast)$ for $v \in C^\infty_c(U)$. This gives
	\[
	\int_U(Lu - f)v = 0.
	\]
	So $Lu = f$ in $U$ everywhere. Hence $u \in H^1_0(U)$, $u|_{\partial U} = T(u) = 0$ in $L^2(\partial U)$.
\end{proofbox}

The main tool is the following.

\begin{theorem}[Lax-Milgram]
	Let $H$ be a real Hilbert space with inner product $(\cdot, \cdot)$ and $B : H \times H \to \mathbb{R}$ a bilinear form that is:
	\begin{itemize}
		\item bounded: $|B[u, v]| \leq \alpha \|u\|_H \|v\|_H$ for $\alpha > 0$,
		\item coercive: $B[u, u] \geq \beta \|u\|^2$ for $\beta > 0$.
	\end{itemize}
	Let $F \in H^{\ast}$ be a bounded linear form. Then there exists unique $u \in H$ such that $B[u, \cdot] = F$. Moreover $\|u\|\leq \| F\|$.
\end{theorem}

We can apply this to the simplest case of the Dirichlet problem

\begin{corollary}
	Let $L$ be in divergence form with $b_i = 0$ and $c \geq 0$, with $a_{ij}$ bounded and uniformly elliptic.

	Then Lax-Milgram applies with $H = H^1_0(U)$, with $B$ defined in the weak formulation and $F = \langle f , \cdot \rangle$ in $L^2$.

	Then there exists a unique $u \in H^1_0(U)$ weak solution.
\end{corollary}

We first prove the corollary.

\begin{proofbox}
	We check three things: $B$ is bounded as a bilinear form $H^1_0 \times H^1_0 \to \mathbb{R}$; $B$ is coercive on $H^1_0$; and $F$ is bounded as a linear form on $H^1_0$.

	(i) Note that
	\begin{align*}
		B[u, v] &= \int (\alpha_{ij} (\partial_{x_i} u) (\partial_{x_j} v) + cuv) \\
			&\leq \bar a \|\nabla u\|_{L^2} \|\nabla v\|_{L^2} + \bar c \|u\|_{L^2} \|v\|_{L^2} \\
			&\leq \alpha \|u\|_{H^1_0} \|v\|_{H^1_0}.
	\end{align*}
	
	(ii) Look at $B[u, u]$:
	\begin{align*}
		B[u, u] &= \int (a_{ij} (\partial_{x)i} u)(\partial_{x_j} u) + c u^2) \\
			&\geq \theta \|\nabla u\|^2_{L^2} \geq C \theta \|u\|^2_{H^1_0},
	\end{align*}
	from $\|u\|_{L^{2^{\ast}}} \leq C \|\nabla u\|_{L^2}$ for $u \in W^{1,2}_0(U)$.

	Then (iii) gives
	\begin{align*}
		|F(v)| &= \left| \int_U f v\right| \leq \|f\|_{L^2} \|v\|_{L^2} \\
		       &\leq C \|f\|_{L^2} \|v\|_{H^1_0}.
	\end{align*}
\end{proofbox}

Now lets prove Lax-Milgram.

\begin{proofbox}
	Assume that $B[u, v] = B[v, u]$ by symmetrising. The boundedness and symmetry and coercivity means that $B$ defines anther inner product, equivalent to the first one.

	So Riesz representation theorem in $H^1_0(U)$ endowed with an inner product $B$ and $F$ is uniquely represented by $u \in H^1_0(U)$, hence $B[u, \cdot] = F$.
% lecture 15

	If $B$ is not symmetric, given $u \in H$, $v \mapsto B[u, v]$ is bounded and linear, so it is uniquely represented by some $w \in H$, so 
	\[
		B[u, \cdot] = (w, \cdot).
	\]
	Let $A$ be the map $u \mapsto w$, from $H \to H$. Then $A$ is linear as $u \mapsto B[u, \cdot]$ is linear, and $A$ is bounded, since
	\[
		\|Au\|^2 = B[u, Au] \leq \beta \|u\| \|A u\|,
	\]
	so $\|A u\| \leq \beta \|u\|$. Moreover $A$ is coercive, as by testing on $u$,
	\[
		\alpha \|u\|^2 \leq B[u, u] = (Au, u) \leq \|Au\| \|u\|,
	\]
	hence $\|Au\| \geq \alpha \|u\|$. This shows injectivity.

	Observe that $(\Img A)^{\perp} = \{0\}$. Indeed if $v \perp \Img A$, then $0 = (v, Av) = B[v, v] \geq \alpha \|v\|^2$, so $v = 0$.

	Moreover $\Img (A)$ is closed, as if $(A u_n)$ is Cauchy, then by coercivity $(u_n)$ is Cauchy, so $u_n \to u_\infty$, hence $A u_n \to A u_{\infty}$.

	So $\Img (A)$ is a closed subspace with trivial orthogonal space, so $\Img (A) = H$. To conclude, we see that $A : H \to H$ is linear and invertible, since $\|A^{-1}\| \leq \alpha^{-1}$. So $F \in H^{\ast}$ is uniquely isometrically represented by $w \in H$, and the solution is $u = A^{-1}w$. Moreover
	\[
	\|u\|_H \leq \|A^{-1}\| \|w\|_H \leq \alpha^{-1} \|F\|_{H^{\ast}}.
	\]
\end{proofbox}

\begin{remark}
	Lax-Milgram is related to the calculus of variations. Taking $B$ symmetric and coercive, then $B[u, \cdot] = F(\cdot)$ is the Euler-Lagrange equation of
	\[
		\inf_{H_0} \frac{B[u, u]}{2} - F(u).
	\]
\end{remark}

\subsection{Dirichlet Problem in the Degenerate Case}%
\label{sub:dir_deg}

Let $L$ be in divergence form, $b_i \neq 0$, $c$ having no sign and being $\theta$-elliptic.

We can prove the following energy estimate: for $u \in H^1_0(U)$, then
\[
	B[u, u] \geq \beta \|u\|^2_{H^1(U)} - \gamma \|u\|^2_{L^2(U)},
\]
for some $\beta, \gamma > 0$.

\begin{proofbox}
	We have
	\begin{align*}
		B[u, u] &= \int_U \left[ a_{ij}(\partial_i u) (\partial_j u) + b_i(\partial_i u) u + c u^2 \right] \\
			&\geq \theta \int_U |\nabla u|^2 - \bar b \sum_{i = 1}^n \int|\partial_i u| |u| - \bar c \int u^2 \\
			&\geq \frac{\theta}{2} \int |\nabla u|^2 - \left( \frac{\bar b^2}{2} \frac{n}{\theta} + \bar c \right) \int u^2,
	\end{align*}
	where $\bar b$ is the upper bound on all $|b_i|$, and $\bar c$ being $|c|$.
\end{proofbox}

\begin{remark}
	If this is true with $\gamma = 0$, then $L_\mu u = Lu + \mu u$ satisfies $\gamma_\mu = 0$ for $\mu \geq \gamma$. Indeed,
	\[
		B_\mu[u, v] = B[u, v] + \mu \int uv,
	\]
	so Lax-Milgram applies to $L_\mu u = f$, $u|_{\partial U} = 0$ for $\mu \geq \gamma$.
\end{remark}

\begin{definition}
	Let $H$ be a Hilbert space. Then a bounded linear operator $K : H \to H$ is said to be \emph{compact}\index{compact} if $(u_m)$ bounded in $H$ means that $(K u_m)$ has a subsequence converging strongly.
\end{definition}

\begin{remark}
	\begin{enumerate}
		\item[]
		\item Compact operators are infinite dimensional extensions of matrices. Operators are compact $\iff$ they are a limit of finite rank operators.
		\item By Rellich-Kondrashov theorem, if $K : L^2(U) \to L^2(U)$ is linear and bounded and $K$ is bounded $L^2(U) \to H^1(U)$, then $K$ is compact $L^2 \to L^2$.
	\end{enumerate}
\end{remark}

\begin{theorem}[Fredholm Theory for Compact Operators]
	Let $K : H \to H$ be compact in $H$ real Hilbert. Then,
	\begin{enumerate}[\normalfont(i)]
		\item If $T = \id - K$, then $\Ker T$ is finite dimensional.
		\item $\Img T$ is closed.
		\item $\Img T = (\Ker T^{\ast})^{\perp}$, where $T^{\ast} = \id - K^{\ast}$, and $(K^{\ast} u, v) = (u, K v)$ for all $u, v \in H$.
		\item $\Ker T = \{0\} \iff \Img T = H$.
		\item $\dim \Ker T = \dim \Ker T^{\ast}$.
	\end{enumerate}
\end{theorem}

\begin{proofbox}
	
	
	(i) Recall Riesz lemma, that the unit ball is compact if and only if it is finite dimensional.

	Consider $\Ker T$ as a subspace of $H$, and $(u_m)$ be a bounded sequence in $\Ker T$. Then $(u_m) = (K u_m)$, but as $K$ is compact it has a convergent subsequence.

	But then $(u_m)$ has a convergent subsequence, which means $\Ker T$ is finite dimensional.

	(ii) Consider $(u_m)$ a converging sequence in $\Img T$, so there exists $(v_m)$ in $H$ so that
	\[
	u_m = v_m - K v_m.
	\]
	Note that $H = (\Ker T) \oplus (\Ker T)^{\perp}$, so we can decompose $v_m = w_m + h_m$, where $w_m \in \Ker T$, $h_m \perp \Ker T$.

	If $h_m$ is bounded, then $u_m = h_m - K h_m$. But as $K$ is compact, the latter converges so $(h_m)$ has a subsequence that is convergent, hence $h_{m_k} \to h_\infty$. Then $u_\infty = T h_\infty \in \Img T$.

	If $(h_m)$ is not bounded, we find a subsequence so that $0 \leq \|h_{m_k}\| \uparrow \infty$, and then $\tilde h_{m_k} = h_{m_k} / \|h_{m_k}\|$ satisfies
	\[
	\tilde h_{m_k} - K \tilde h_{m_k} = \frac{u_{m_k}}{ \|h_{m_k}\|} \to 0.
	\]
	But $h_{m_k}$ is bounded, so a subsequence converges to $h_\infty$ with unit norm, and $h_\infty \perp \Ker T$. Taking the limit, $h_\infty - K h_\infty = 0$, which is a contradiction as $h_\infty \in \Ker T$ as well.

	(iii) We always have $(\Ker T^{\ast}) = (\Img T)^{\perp}$, so
	\[
	\Img T = \overline{\Img T} = ((\Img T)^{\perp})^{\perp} = (\Ker T^{\ast})^{\perp}.
	\]

	(iv) Observe that by (iii) and $K^{\ast}$ compact, we only need to prove
	\[
		\Img T = H \implies \Ker T = \{0\},
	\]

	as we can apply this to the adjoint problem. There exists a smallest $k_0 \geq 0$ such that $\Ker T^{k_0} = \Ker T^{k_0 + 1}$. If $k_0 \geq 1$, we have a contradiction.
% lecture 16

	So we claim there exists a smallest $k_0 \geq 0$ such that
	\[
	\Ker T^{k_0} = \Ker T^{k_0 + 1}.
	\]
	If not, choose an orthonormal sequence $(u_k)$, with $u_k \in \Ker T^{k+1}$. Then for $k \geq 0$, $l \geq 1$,
	\[
	K u_{k + l} - K u_k = T u_k - T u_{k+l} - u_k + u_{k+l} \in \Ker T^{k+l} + u_{k+l}.
	\]
	Hence we find that
	\[
	\|K u_{k+l} - K u_k\|^2 \geq \|u_{k+;}\|^2 = 1.
	\]
	So the sequence $(K u_k)$ has no converging subsequence, contradiction. So $k_0$ can be defined above.

	Let us prove that $k_0 = 0$ to conclude that $\{0\} = \Ker T^{0} = \Ker T$. If $k_0 \geq 1$, then there exists $u \in \Ker T^{k_0} \setminus \Ker T^{k_0 - 1}$.

	Since $\Img T = H$, there exists $v$ with $Tv = u$. Then $v \in \Ker T^{k_0 + 1} = \Ker T^{k_0}$, so in fact $u \in \Ker T^{k_0 - 1}$, which is a contradiction.

	(v) We want to prove that
	\[
	\dim \Ker T = \dim \Ker T^{\ast}.
	\]
	We know that if one is zero, then the other must be zero, from (iii) and (iv). Let $m_1 = \dim \Ker T$, $m_2 = \dim \Ker T^{\ast}$, where $m_1, m_2 \geq 1$. Then denote $(f_k)_{k = 1}^{m_1}$, $(g_k)_{k = 1}^{m_2}$ to be orthonormal bases of each kernels. Then let
	\[
	\tilde K = K + (\cdot, f_1) g_1, \qquad \tilde K^{\ast} = K^{\ast} + (\cdot, g_1) f_1.
	\]
	We can check that
	\[
	\dim \Ker (\id - \tilde K) = m_1 - 1, \qquad \dim \Ker (\id - \tilde K^{\ast}) = m_2 - 1.
	\]
	$\tilde K$, $\tilde K^{\ast}$ are compact operators, as they are finite rank modifications of compact operators. We can continue until the index is zero, then both must be zero.
\end{proofbox}

We have the following application.

\begin{corollary}[Fredholm Alternative for Dirichlet]
	Consider $Lu = f$ for $u$ open bounded, and $u|_{\partial U} = 0$, where $\partial U$ is $C^1$.

	Let $f \in L^2(U)$, and $a_{ij}, b_j, c \in L^{\infty}(U)$, where $L$ is uniformly elliptic. Then either:
	\begin{itemize}
		\item There is a unique weak solution $u \in H_0^1 (U)$ to the equation for all $f \in L^2(U)$,
		\item Or the homogeneous problem $f = 0$ has at least one non-zero weak solution.
	\end{itemize}
	In the second case the set of homogeneous weak solutions $N$ is finite dimensional, non-trivial, with the same dimension as $N^{\ast}$, the set of homogeneous weak solutions to $L^{\ast} u = 0$, where $\langle Lu, v\rangle = \langle u, L^{\ast} v\rangle$, so $B^{\ast}[u, v] = B[v, u]$.

	Finally the Dirichlet problem $(\ast)$ with RHS $f \in L^2(U)$ has weak solutions if and only if $f \perp N^{\ast}$. Here solutions are $u_0 + N$, where $u_0$ is a particular weak solution.
\end{corollary}

\begin{remark}
	This looks like solving $Ax = b$; there is a unique solution if $b$ is not in the kernel of $A$.
\end{remark}

\begin{proofbox}
	We know that $B$ in the weak formulation satisfies the energy estimate, so that
	\[
	L_\mu w = Lw + \mu w = f
	\]
	has a unique weak solution $w \in H_0^1(U)$ for all $f \in L^2(U)$, for $\mu = \gamma + 1$. Recall the energy estimate:
	\[
		B[u, u] \geq C \|\nabla u\|^2_{L^2} - \gamma \|u\|^2_{L^2}.
	\]
	Hence there is $w = L_\mu^{-1} g \in H^1_0(U)$ that is constructed. Recall that
	\[
	\|w\|_{H^1_0(U)} \leq C \|g\|_{L^2(U)},
	\]
	so the linear operator $L_\mu^{-1}$ is bounded and compact by Rellich-Kondrashov.

	Rewrite the Dirichlet problem $Lu = f$ as
	\[
	L_\mu u = \mu u + f.
	\]
	Hence we are searching for $u \in H^1_0(U)$, such that
	\[
		\mu = L_\mu^{-1} f + \mu L_\mu^{-1} u \iff (\id - \mu L_{\mu}^{-1})u = L_\mu^{-1} f = \mu^{-1} K f, \tag{$\ast\ast$}
	\]
	where $K = \mu L_{\mu}^{-1}$. Thus applying (iv) from the last theorem in $H = L^2(U)$, either $\Ker (\id - K) = \{0\}$ and $\Img (\id - K) = H$, so $(\ast\ast)$ always has a solution, or $\Ker (\id - K)$ is non-trivial.

	If we have a solution $u$ to $(\ast\ast)$, this corresponds to a weak solution to the initial problem. Otherwise, let $\Ker(\id - K) = N$ in $L^2(U)$. If $u = \mu L_\mu^{-1} u$, then $u \in H^1_0(U)$, and by definition $\tilde u = \mu L_{\mu}^{-1}u$ satisfies
	\[
		B[\tilde u, \cdot] + \mu (\tilde u, \cdot) = \mu (u, \cdot),
	\]
	which as $\mu = \tilde \mu$ rewrites as $B[u, \cdot] = 0$, so $u$ is a homogeneous solution to the initial problem.

	Similarly $\Ker(\id - K^{\ast}) = N^{\ast}$.

	The first case corresponds to $N = N^{\ast} = \{0\}$, and $\Img (\id - K) = H$, so the solution provided is
	\[
	u = (\id - K)^{-1} \mu K f \in H^1_0(U).
	\]
	In the other case, $\dim N = \dim N^{\ast} \geq 1$, and
	\[
	\Img (\id - K) = \Ker (\id - K^{\ast})^{\perp} = (N^{\ast})^{\perp}.
	\]
	We show $Kf \perp N^{\ast} \iff f \perp N^{\ast}$.
% lecture 17
	Indeed, $v \in N^{\ast} \iff v = K^{\ast} v$. For all $v \in N^{\ast}$,
	\[
		(f, v) = (f, K^{\ast} v) = (Kf, v).
	\]
\end{proofbox}

\begin{remark}
	The arguments above imply that for all $\lambda \in \mathbb{R}$,
	\[
	L_{-\lambda}u = (L - \lambda)u = f
	\]
	has either a unique solution for all $f$, or no solutions or multiple solutions.
\end{remark}

Note that we can complexify everything, by letting
\[
	(u, v)_{L^2(U)} = \int_U \bar u v,
\]
for $u, v$ $\mathbb{C}$-valued, and
\[
\langle u, v \rangle_{H^1_0(U)} = \int_U (\bar u v + \overline{D u} Dv ).
\]
This is useful as $\mathbb{C}$ is algebraically closed, and not $\mathbb{R}$, so we miss rotation matrices working over $\mathbb{R}$.

We claim that after complexifying, everything we have proven still works.

\begin{theorem}[Spectrum of $L$]
	With all the assumptions as before, after complexifying,
	\begin{enumerate}[\normalfont(i)]
		\item There is at most countably many $\lambda \in \Sigma \subseteq \mathbb{C}$ so that
			\[
				(L - \lambda) u = f
			\]
			does not have a unique $u \in H^1_0(U)$ solution for all $f \in L^2$.
		\item If $\Sigma$ is infinite, then we can write it as a sequence $(\lambda_k)$ where $|\lambda_k| \to \infty$.
		\item Each $\lambda \in \Sigma$ corresponds to a finite dimensional space eigenspace, $\mathcal{C}(\lambda)$,
			\[
				\mathcal{C}(\lambda) = \{ u \in H^1_0(U) \mid (L - \lambda) u = 0 \iff B[u, \cdot] = \lambda(u, \cdot) \}.
			\]
		\item If $a_{ij} = \overline{a_{ji}}$ for all $i, j$, $b_i = 0$ and $c = \bar c$, then
			\[
			\Sigma \subset [c, +\infty) \subset \mathbb{R}.
			\]
	\end{enumerate}	
\end{theorem}

\begin{remark}
	\begin{enumerate}
		\item[]
		\item If we have an unbounded operator $L$, then $L : L^2 \not L^2$, for $u \in L^2$.
		\item The proof establishes a resolvent estimate:
			\[
			\|L_{\mu}^{-1}\|_{L^2(U) \to L^2(U)} \leq \frac{C}{1 + \mu},
			\]
			as $\mu \to \infty$. In the symmetric case,
			\[
			\|L_\mu^{-1}\| \leq \frac{1}{d(\mu, \Sigma)}.
			\]
		\item If $L = - \Delta$ in $U$ open bounded and $C^1$ boundary, then $\Sigma = \{(\lambda_k)\} \subseteq \mathbb{R}_+$, and we can order it as $0 < \lambda_1 < \cdots < \lambda_k$ are the \emph{harmonic frequencies}\index{harmonic frequencies} of the domain.

			This can be thought of as the frequencies of a $U$-shaped drum. Is the shape determined by the sequence of harmonic frequencies, i.e. can you hear the shape of a drum?

			If $U$ is compact analytic, then the answer is yes by Zelditch, and no for convex polygons.
	\end{enumerate}	
\end{remark}

\begin{proofbox}
	Given $\lambda \in \mathbb{C}$, if $\Re \lambda \leq - \gamma$, where recall $\gamma$ is the constant in our energy estimate, then $L_{-\lambda} = L - \lambda$ is coercive, i.e.
	\[
		B_{-\lambda}[u, u] \geq \frac{\theta}{2} \|Du\|_{L^2}^2.
	\]
	Hence there exists unique $u \in H^1_0(U)$ for all $f \in L^2(U)$ with
	\[
		(L - \lambda) u = f \iff B_{-\lambda}[u, \cdot] = (f, \cdot).
	\]
	So $\Sigma \subseteq \{\Re \lambda \geq -\gamma\}$.

	To prove (iii), use the previous theorem
	\[
		(L - \lambda) u = f \iff [\id - (\mu + \lambda)K]u = K f,
	\]
	where $K = L_{\mu}^{-1}$, and $\mu = \gamma \vee |\lambda| + 1$. If the space of homogeneous solutions is not trivial, then $N, N^{\ast}$ are not trivial, but we know that $\dim N < \infty$.

	To prove (i) and (ii), we claim the following: for all $M >0$, $\Sigma \cap B_{\mathbb{C}}(0, M)$ is finite. This proves both statements.

	The proof is by contradiction. Assume we have $(\lambda_k)$ infinite and pairwise distinct in $\Sigma \cap B(0, M)$. Choose $\mu = \gamma \vee M + 1$. Then we can reformulate $(L - \lambda_k)  u = f$ as
	\[
		(\id - (\lambda_k + \mu)K)u = Kf,
	\]
	where $K = L_\mu^{-1}$, for all $k \geq 1$. Since $\lambda_k \in \Sigma$, $N$ is not trivial. Here
	\[
	N = \ker (\id - (\lambda_k + \mu)K).
	\]
	This means that $(\lambda_k + \mu)^{-1} = \tilde \lambda_{k}$ is an eigenvalue with a finite-dimensional eigenspace, of $K$.

	Pick inductively $u_k \in L^2(U) \setminus \{0\}$ such that
	\[
	K u_ = \frac{1}{\lambda_k + \mu} u_k,
	\]
	and $u_k$ is at distance at least $1/2$ of the span of $\{u_1, \ldots, u_{k-1}\}$. Hence
	\begin{align*}
		\|K u_{k+l} - K u_k\|_{L^2(U)} &= \|\tilde \lambda_{k + l} u_{k+l} - \tilde \lambda_{k} u_k\| \\
					       &= |\tilde \lambda_{k+l}| \left\|u_{k+l} - \frac{\tilde \lambda_k}{\tilde \lambda_{k+l}} u_k\right\| \\
					       &\geq \frac{1}{2(\mu + M)},
	\end{align*}
	which means that $(Ku_k)$ has no converging subsequence, a contradiction to $K$ being compact.

	(iv) If $\overline{a_{ij}} = a_{ji}$, $b_i = 0$ and $c = \bar c$, then $K = K^{\ast}$, which we can check. So,
	\[
	\tilde \lambda_k = \overline{\tilde \lambda_k} \implies \lambda_k \in \mathbb{R}.
	\]
\end{proofbox}

\subsection{Regularity Theory of Dirichlet Problem}%
\label{sub:rtp}

Take the problem $Lu = f$. This we solved in $H^1_0(U)$. When can we show that this is a strong solution in $C^2$ or $C^k$?

We begin with the core idea in a simplified setting: if $u \in C_c^\infty(U)$ and $-\Delta u = f \in L^2$, then 
\begin{align*}
	\int_U f^2 &= \int_U (\Delta u)^2 = \int \left( \sum_{i = 1}^n \partial_{ii}^2 u \right) \left( \sum_{j = 1}^n \partial_{jj}^2 u \right).
\end{align*}
Now we can do integration by parts twice to find that
\begin{align*}
	\int f^2 &= \int (\Delta u)^2 = \int \sum_{i,j = 1}^n (\partial_{ij}^2 u)^2.
\end{align*}
This shows we can control the full second-order regularity of $f$, with the $L^2$ of $\Tr \nabla u^2$ and $\nabla u^2$.

% lecture 18

\newpage

\printindex

\end{document}
